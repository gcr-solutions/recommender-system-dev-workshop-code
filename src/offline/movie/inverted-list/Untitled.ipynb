{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: Pandas in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (1.1.5)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from Pandas) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from Pandas) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from Pandas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from python-dateutil>=2.7.3->Pandas) (1.14.0)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-0.8.7-py3-none-any.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 15.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from fsspec) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->fsspec) (2.2.0)\n",
      "Installing collected packages: fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.7.1\n",
      "    Uninstalling fsspec-0.7.1:\n",
      "      Successfully uninstalled fsspec-0.7.1\n",
      "Successfully installed fsspec-0.8.7\n"
     ]
    }
   ],
   "source": [
    "!pip install -U Pandas\n",
    "!pip install -U fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s,%(msecs)d %(levelname)-8s [%(filename)s:%(lineno)d] %(message)s',\n",
    "                    datefmt='%Y-%m-%d:%H:%M:%S',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_s3(filename, bucket, key):\n",
    "    with open(filename, 'rb') as f:  # Read in binary mode\n",
    "        s3.upload_fileobj(f, bucket, key)\n",
    "\n",
    "    return \"s3://{}/{}\".format(bucket, key)\n",
    "\n",
    "\n",
    "def download_from_s3(filename, bucket, key):\n",
    "    with open(filename, 'wb') as f:\n",
    "        return s3.download_fileobj(bucket, key, f)\n",
    "\n",
    "\n",
    "def list_s3_by_prefix_v2(s3_path, filter_func=None):\n",
    "    bucket, key_prefix = get_bucket_key_from_s3_path(s3_path)\n",
    "    return list_s3_by_prefix(bucket, key_prefix, filter_func)\n",
    "\n",
    "\n",
    "def list_s3_by_prefix(bucket, key_prefix, filter_func=None):\n",
    "    next_token = ''\n",
    "    all_keys = []\n",
    "    while True:\n",
    "        if next_token:\n",
    "            res = s3.list_objects_v2(\n",
    "                Bucket=bucket,\n",
    "                ContinuationToken=next_token,\n",
    "                Prefix=key_prefix)\n",
    "        else:\n",
    "            res = s3.list_objects_v2(\n",
    "                Bucket=bucket,\n",
    "                Prefix=key_prefix)\n",
    "\n",
    "        if 'Contents' not in res:\n",
    "            break\n",
    "\n",
    "        if res['IsTruncated']:\n",
    "            next_token = res['NextContinuationToken']\n",
    "        else:\n",
    "            next_token = ''\n",
    "\n",
    "        if filter_func:\n",
    "            keys = [\"s3://{}/{}\".format(bucket, item['Key']) for item in res['Contents'] if filter_func(item['Key'])]\n",
    "        else:\n",
    "            keys = [\"s3://{}/{}\".format(bucket, item['Key']) for item in res['Contents']]\n",
    "\n",
    "        all_keys.extend(keys)\n",
    "\n",
    "        if not next_token:\n",
    "            break\n",
    "    print(\"find {} files in s3://{}/{}\".format(len(all_keys), bucket, key_prefix))\n",
    "    return all_keys\n",
    "\n",
    "\n",
    "def get_bucket_key_from_s3_path(s3_path):\n",
    "    m = re.match(r\"s3://(.*?)/(.*)\", s3_path)\n",
    "    return m.group(1), m.group(2)\n",
    "\n",
    "\n",
    "def process_expend_file(expend_s3_path):\n",
    "    logging.info(\"process_expend_file() enter, expend_s3_path:{}\".format(expend_s3_path))\n",
    "    expand_dict = pd.read_excel(expend_s3_path, sheet_name=None)  # set sheet_name=None, read all sheets\n",
    "    selected_columns = ['节目id', '导演', '演员', '受欢迎度', '票数', '评分', '等级']\n",
    "\n",
    "    expand_data_df_arr = []\n",
    "    for sheet_name in expand_dict.keys():\n",
    "        logging.info(\"now process sheet: {}\".format(sheet_name))\n",
    "        df = expand_dict[sheet_name][selected_columns]\n",
    "        expand_data_df_arr.append(df)\n",
    "    expand_data_df = pd.concat(expand_data_df_arr, axis=0, ignore_index=True)\n",
    "    logging.info(\"process_expend_file() return dataFrame, len: {}\".format(len(expand_data_df)))\n",
    "    expand_data_renamed_df = expand_data_df.rename(columns={'节目id': 'program_id',\n",
    "                                                            '导演': 'director',\n",
    "                                                            '演员': 'actor',\n",
    "                                                            '受欢迎度': 'popularity',\n",
    "                                                            '票数': 'ticket_num',\n",
    "                                                            '评分': 'score',\n",
    "                                                            '等级': 'level'})\n",
    "    logging.info(\"expand df columns={}\".format(expand_data_renamed_df.columns))\n",
    "    return expand_data_renamed_df\n",
    "\n",
    "\n",
    "def process_basic_file(basic_s3_path):\n",
    "    logging.info(\"process_basic_file() enter, process_basic_file:{}\".format(process_basic_file))\n",
    "    df = pd.read_csv(basic_s3_path)\n",
    "    logging.info(\"basic df columns={}\".format(df.columns))\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_df(basic_s3_files, expend_s3_files):\n",
    "    expand_data_df = pd.concat([process_expend_file(expend_s3_path) for expend_s3_path in expend_s3_files],\n",
    "                               axis=0, ignore_index=True).drop_duplicates('program_id')\n",
    "\n",
    "    basic_df = pd.concat([process_basic_file(basic_s3_path) for basic_s3_path in basic_s3_files],\n",
    "                         axis=0, ignore_index=True).drop_duplicates('program_id')\n",
    "\n",
    "    df_merged = pd.merge(left=basic_df, right=expand_data_df, on='program_id', how='left')\n",
    "    logging.info(\"df_merged len: {}\".format(len(df_merged)))\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "def gen_pickle_files(basic_s3_path, expend_s3_path, out_s3_path):\n",
    "    logging.info(f\"gen_pick_files(), \"\n",
    "                 f\"\\nbasic_s3_path={basic_s3_path}, \"\n",
    "                 f\"\\nexpend_s3_path={expend_s3_path}, \"\n",
    "                 f\"\\nout_s3_path={out_s3_path}\")\n",
    "\n",
    "    df = prepare_df(basic_s3_path, expend_s3_path)\n",
    "    dicts_1 = gen_movie_id_movie_property_dict(df)\n",
    "    dicts_2 = gen_movie_properties_to_movie_ids_dict(df)\n",
    "    dicts_all = dicts_1\n",
    "    dicts_all.update(dicts_2)\n",
    "    bucket, out_prefix = get_bucket_key_from_s3_path(out_s3_path)\n",
    "    for dict_name, dict_val in dicts_all.items():\n",
    "        file_name = f'{dict_name}.pickle'\n",
    "        # print(\"pickle =>\", file_name)\n",
    "        out_file = open(file_name, 'wb')\n",
    "        pickle.dump(dict_val, out_file)\n",
    "        out_file.close()\n",
    "        # s3_url = S3Uploader.upload(file_name, out_s3_path)\n",
    "        s3_url = write_to_s3(file_name, bucket, f'{out_prefix}/{file_name}')\n",
    "        logging.info(\"write {}\".format(s3_url))\n",
    "    logging.info(f\"generated {len(dicts_all)} pickle files\")\n",
    "\n",
    "\n",
    "def gen_movie_id_movie_property_dict(df):\n",
    "    movie_id_movie_property_dict = {}\n",
    "    for row in df.iterrows():\n",
    "        item_row = row[1]\n",
    "        program_id = str(item_row['program_id'])\n",
    "        program_dict = {\n",
    "            'director': get_single_item(item_row['director']),\n",
    "            'level': get_single_item(item_row['level']),\n",
    "            'year': get_single_item(item_row['release_year']),\n",
    "            'actor': get_actor(item_row['actor']),\n",
    "            'category': get_category(item_row['category_property']),\n",
    "            'language': get_single_item(item_row['language'])\n",
    "        }\n",
    "        movie_id_movie_property_dict[program_id] = program_dict\n",
    "\n",
    "    result_dict = {\n",
    "        'movie_id_movie_property_dict': movie_id_movie_property_dict\n",
    "    }\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def sort_by_score(df):\n",
    "    df['popularity'].fillna(0, inplace=True)\n",
    "    df['ticket_num'].fillna(0, inplace=True)\n",
    "    df['score'].fillna(0, inplace=True)\n",
    "\n",
    "    df['popularity_log'] = np.log1p(df['popularity'])\n",
    "    df['ticket_num_log'] = np.log1p(df['ticket_num'])\n",
    "    popularity_log_max = df['popularity_log'].max()\n",
    "    popularity_log_min = df['popularity_log'].min()\n",
    "    ticket_num_log_max = df['ticket_num_log'].max()\n",
    "    ticket_num_log_min = df['ticket_num_log'].min()\n",
    "\n",
    "    df = df.drop(['popularity', 'ticket_num'], axis=1)\n",
    "\n",
    "    score_max = df['score'].max()\n",
    "    score_min = df['score'].min()\n",
    "    df['popularity_scaled'] = ((df['popularity_log'] - popularity_log_min) / (\n",
    "                popularity_log_max - popularity_log_min)) * 10\n",
    "    df['ticket_num_scaled'] = (df['ticket_num_log'] - ticket_num_log_min) / (\n",
    "                ticket_num_log_max - ticket_num_log_min) * 10\n",
    "    df['score_scaled'] = ((df['score'] - score_min) / (score_max - score_min)) * 10\n",
    "\n",
    "    df['cal_score'] = df['popularity_scaled'] + df['ticket_num_scaled'] + df['score_scaled']\n",
    "\n",
    "    df_with_score = df.drop(\n",
    "        ['popularity', 'ticket_num', 'score', 'popularity_scaled', 'ticket_num_scaled', 'score_scaled'], axis=1)\n",
    "    df_sorted = df_with_score.sort_values(by='cal_score', ascending=False)\n",
    "    return df_sorted\n",
    "\n",
    "\n",
    "def gen_movie_properties_to_movie_ids_dict(df):\n",
    "    df_sorted = sort_by_score(df)\n",
    "\n",
    "    movie_director_movie_ids_dict = {}\n",
    "    movie_language_movie_ids_dict = {}\n",
    "    movie_level_movie_ids_dict = {}\n",
    "    movie_year_movie_ids_dict = {}\n",
    "\n",
    "    movie_category_movie_ids_dict = {}\n",
    "    movie_actor_movie_ids_dict = {}\n",
    "\n",
    "    for row in df_sorted.iterrows():\n",
    "        item_row = row[1]\n",
    "        # program_id = {\"id\": item_row['program_id'], \"score\": item_row['cal_score'] }\n",
    "        program_id = item_row['program_id']\n",
    "        for key in [item for item in get_single_item(item_row['director']) if item is not None]:\n",
    "            movie_director_movie_ids_dict.setdefault(key, []).append(program_id)\n",
    "\n",
    "        for key in [item for item in get_single_item(item_row['level']) if item is not None]:\n",
    "            movie_level_movie_ids_dict.setdefault(key, []).append(program_id)\n",
    "\n",
    "        for key in [item for item in get_single_item(item_row['release_year']) if item is not None]:\n",
    "            movie_year_movie_ids_dict.setdefault(key, []).append(program_id)\n",
    "\n",
    "        for key in [item for item in get_single_item(item_row['language']) if item is not None]:\n",
    "            movie_language_movie_ids_dict.setdefault(key, []).append(program_id)\n",
    "\n",
    "        for key in [item for item in get_category(item_row['category_property']) if item is not None]:\n",
    "            movie_category_movie_ids_dict.setdefault(key, []).append(program_id)\n",
    "\n",
    "        for key in [item for item in get_actor(item_row['actor']) if item is not None]:\n",
    "            movie_actor_movie_ids_dict.setdefault(key, []).append(program_id)\n",
    "\n",
    "    result_dict = {\n",
    "        'movie_director_movie_ids_dict': movie_director_movie_ids_dict,\n",
    "        'movie_language_movie_ids_dict': movie_language_movie_ids_dict,\n",
    "        'movie_level_movie_ids_dict': movie_level_movie_ids_dict,\n",
    "        'movie_year_movie_ids_dict': movie_year_movie_ids_dict,\n",
    "        'movie_category_movie_ids_dict': movie_category_movie_ids_dict,\n",
    "        'movie_actor_movie_ids_dict': movie_actor_movie_ids_dict\n",
    "    }\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def get_actor(actor_str):\n",
    "    if not actor_str or str(actor_str).lower() in ['nan', 'nr', '']:\n",
    "        return [None]\n",
    "    actor_str = re.sub(r\"['\\\"\\[\\]]\", '', actor_str)\n",
    "    actor_arr = actor_str.split(',')\n",
    "    return [item.strip().lower() for item in actor_arr]\n",
    "\n",
    "\n",
    "def get_category(category_property):\n",
    "    if not category_property or str(category_property).lower() in ['nan', 'nr', '']:\n",
    "        return [None]\n",
    "    if not category_property:\n",
    "        return [None]\n",
    "    return [item.strip().lower() for item in category_property.split(',')]\n",
    "\n",
    "\n",
    "def get_single_item(item):\n",
    "    if not item or str(item).lower().strip() in ['nan', 'nr', '']:\n",
    "        return [None]\n",
    "    return [str(item).lower().strip()]\n",
    "\n",
    "\n",
    "def get_expend_file_from_basic(basic_s3_path):\n",
    "    return re.sub(r\"/basic/(\\d+).csv\", r\"/expand/\\1.xlsx\", basic_s3_path)\n",
    "\n",
    "\n",
    "def get_segment(basic_s3_path):\n",
    "    m = re.search(r\"/basic/(\\d+).csv\", basic_s3_path)\n",
    "    s = 0\n",
    "    if m:\n",
    "        s = m.group(1)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-17:09:01:46,798 INFO     [<ipython-input-20-1356d01b8830>:10] Received arguments Namespace(bucket='sagemaker-us-east-1-002224604296', mk_region='1')\n",
      "2021-03-17:09:01:46,800 INFO     [<ipython-input-20-1356d01b8830>:27] basic_s3_files=['s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1/system/item-data/basic/1.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1271/system/item-data/basic/1271.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1347/system/item-data/basic/1347.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1686/system/item-data/basic/1686.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1770/system/item-data/basic/1770.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1940/system/item-data/basic/1940.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/2434/system/item-data/basic/2434.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/47/system/item-data/basic/47.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/86/system/item-data/basic/86.csv']\n",
      "2021-03-17:09:01:46,801 INFO     [<ipython-input-20-1356d01b8830>:28] expend_s3_files=['s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1/system/item-data/expand/1.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1271/system/item-data/expand/1271.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1347/system/item-data/expand/1347.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1686/system/item-data/expand/1686.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1770/system/item-data/expand/1770.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1940/system/item-data/expand/1940.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/2434/system/item-data/expand/2434.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/47/system/item-data/expand/47.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/86/system/item-data/expand/86.xlsx']\n",
      "2021-03-17:09:01:46,802 INFO     [<ipython-input-20-1356d01b8830>:29] out_s3_path=s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1/feature/content/inverted-list\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "default_bucket = 'sagemaker-us-east-1-002224604296'\n",
    "default_mk_region = '1'\n",
    "level_1 = 'recommender-system-film-mk'\n",
    "\n",
    "parser.add_argument('--bucket', type=str, default=default_bucket)\n",
    "parser.add_argument('--mk-region', type=str, default=default_mk_region)\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "logging.info('Received arguments {}'.format(args))\n",
    "bucket = args.bucket\n",
    "mk_region = args.mk_region\n",
    "\n",
    "out_s3_path = f's3://{bucket}/{level_1}/{mk_region}/feature/content/inverted-list'\n",
    "input_s3 = f's3://{bucket}/{level_1}/{mk_region}/system/item-data'\n",
    "\n",
    "# basic_s3_files = [f'{input_s3}/basic/{mk_region}.csv']\n",
    "# expend_s3_files = [f'{input_s3}/expand/{mk_region}.xlsx']\n",
    "#\n",
    "basic_s3_files = []\n",
    "expend_s3_files = []\n",
    "all_mk_regions = \"1,1271,1347,1686,1770,1940,2434,47,86\"\n",
    "for mk_rg in all_mk_regions.split(\",\"):\n",
    "    basic_s3_files.append(f's3://{bucket}/{level_1}/{mk_rg}/system/item-data/basic/{mk_rg}.csv')\n",
    "    expend_s3_files.append(f's3://{bucket}/{level_1}/{mk_rg}/system/item-data/expand/{mk_rg}.xlsx')\n",
    "\n",
    "logging.info(f\"basic_s3_files={basic_s3_files}\")\n",
    "logging.info(f\"expend_s3_files={expend_s3_files}\")\n",
    "logging.info(f\"out_s3_path={out_s3_path}\")\n",
    "\n",
    "# gen_pickle_files(basic_s3_files, expend_s3_files, out_s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-17:09:01:48,242 INFO     [<ipython-input-21-78015f09aa6f>:3] gen_pick_files(), \n",
      "basic_s3_path=['s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1/system/item-data/basic/1.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1271/system/item-data/basic/1271.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1347/system/item-data/basic/1347.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1686/system/item-data/basic/1686.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1770/system/item-data/basic/1770.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1940/system/item-data/basic/1940.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/2434/system/item-data/basic/2434.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/47/system/item-data/basic/47.csv', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/86/system/item-data/basic/86.csv'], \n",
      "expend_s3_path=['s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1/system/item-data/expand/1.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1271/system/item-data/expand/1271.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1347/system/item-data/expand/1347.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1686/system/item-data/expand/1686.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1770/system/item-data/expand/1770.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1940/system/item-data/expand/1940.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/2434/system/item-data/expand/2434.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/47/system/item-data/expand/47.xlsx', 's3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/86/system/item-data/expand/86.xlsx'], \n",
      "out_s3_path=s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1/feature/content/inverted-list\n",
      "2021-03-17:09:01:48,243 INFO     [<ipython-input-19-74f10773020b>:59] process_expend_file() enter, expend_s3_path:s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1/system/item-data/expand/1.xlsx\n",
      "2021-03-17:09:01:49,199 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: New Movie\n",
      "2021-03-17:09:01:49,201 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Hot Movie\n",
      "2021-03-17:09:01:49,202 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Movie\n",
      "2021-03-17:09:01:49,205 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: 3D Movie\n",
      "2021-03-17:09:01:49,207 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: French Movie\n",
      "2021-03-17:09:01:49,209 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Documentaries\n",
      "2021-03-17:09:01:49,220 INFO     [<ipython-input-19-74f10773020b>:69] process_expend_file() return dataFrame, len: 2976\n",
      "2021-03-17:09:01:49,221 INFO     [<ipython-input-19-74f10773020b>:77] expand df columns=Index(['program_id', 'director', 'actor', 'popularity', 'ticket_num', 'score',\n",
      "       'level'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:49,223 INFO     [<ipython-input-19-74f10773020b>:59] process_expend_file() enter, expend_s3_path:s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1271/system/item-data/expand/1271.xlsx\n",
      "2021-03-17:09:01:50,341 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: New Movie\n",
      "2021-03-17:09:01:50,343 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Hot Movie\n",
      "2021-03-17:09:01:50,346 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Movie\n",
      "2021-03-17:09:01:50,349 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: 3D Movie\n",
      "2021-03-17:09:01:50,351 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: French Movie\n",
      "2021-03-17:09:01:50,353 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Documentaries\n",
      "2021-03-17:09:01:50,362 INFO     [<ipython-input-19-74f10773020b>:69] process_expend_file() return dataFrame, len: 3667\n",
      "2021-03-17:09:01:50,364 INFO     [<ipython-input-19-74f10773020b>:77] expand df columns=Index(['program_id', 'director', 'actor', 'popularity', 'ticket_num', 'score',\n",
      "       'level'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:50,366 INFO     [<ipython-input-19-74f10773020b>:59] process_expend_file() enter, expend_s3_path:s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1347/system/item-data/expand/1347.xlsx\n",
      "2021-03-17:09:01:51,413 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Movie\n",
      "2021-03-17:09:01:51,417 INFO     [<ipython-input-19-74f10773020b>:69] process_expend_file() return dataFrame, len: 4015\n",
      "2021-03-17:09:01:51,419 INFO     [<ipython-input-19-74f10773020b>:77] expand df columns=Index(['program_id', 'director', 'actor', 'popularity', 'ticket_num', 'score',\n",
      "       'level'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:51,420 INFO     [<ipython-input-19-74f10773020b>:59] process_expend_file() enter, expend_s3_path:s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1686/system/item-data/expand/1686.xlsx\n",
      "2021-03-17:09:01:51,735 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: New Movie\n",
      "2021-03-17:09:01:51,737 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Movie\n",
      "2021-03-17:09:01:51,740 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: 3D Movie\n",
      "2021-03-17:09:01:51,746 INFO     [<ipython-input-19-74f10773020b>:69] process_expend_file() return dataFrame, len: 692\n",
      "2021-03-17:09:01:51,749 INFO     [<ipython-input-19-74f10773020b>:77] expand df columns=Index(['program_id', 'director', 'actor', 'popularity', 'ticket_num', 'score',\n",
      "       'level'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:51,750 INFO     [<ipython-input-19-74f10773020b>:59] process_expend_file() enter, expend_s3_path:s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1770/system/item-data/expand/1770.xlsx\n",
      "2021-03-17:09:01:51,924 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Movie\n",
      "2021-03-17:09:01:51,928 INFO     [<ipython-input-19-74f10773020b>:69] process_expend_file() return dataFrame, len: 245\n",
      "2021-03-17:09:01:51,930 INFO     [<ipython-input-19-74f10773020b>:77] expand df columns=Index(['program_id', 'director', 'actor', 'popularity', 'ticket_num', 'score',\n",
      "       'level'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:51,931 INFO     [<ipython-input-19-74f10773020b>:59] process_expend_file() enter, expend_s3_path:s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1940/system/item-data/expand/1940.xlsx\n",
      "2021-03-17:09:01:52,2 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: New Movie\n",
      "2021-03-17:09:01:52,4 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Movie\n",
      "2021-03-17:09:01:52,6 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: 3D Movie\n",
      "2021-03-17:09:01:52,12 INFO     [<ipython-input-19-74f10773020b>:69] process_expend_file() return dataFrame, len: 11\n",
      "2021-03-17:09:01:52,14 INFO     [<ipython-input-19-74f10773020b>:77] expand df columns=Index(['program_id', 'director', 'actor', 'popularity', 'ticket_num', 'score',\n",
      "       'level'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:52,15 INFO     [<ipython-input-19-74f10773020b>:59] process_expend_file() enter, expend_s3_path:s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/2434/system/item-data/expand/2434.xlsx\n",
      "2021-03-17:09:01:52,473 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Movie\n",
      "2021-03-17:09:01:52,475 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: New Movie\n",
      "2021-03-17:09:01:52,478 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Hot Movie\n",
      "2021-03-17:09:01:52,480 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Arabic Movie\n",
      "2021-03-17:09:01:52,483 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Documentaries\n",
      "2021-03-17:09:01:52,485 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: French Movie\n",
      "2021-03-17:09:01:52,487 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: 3D Movie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-17:09:01:52,498 INFO     [<ipython-input-19-74f10773020b>:69] process_expend_file() return dataFrame, len: 1243\n",
      "2021-03-17:09:01:52,500 INFO     [<ipython-input-19-74f10773020b>:77] expand df columns=Index(['program_id', 'director', 'actor', 'popularity', 'ticket_num', 'score',\n",
      "       'level'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:52,501 INFO     [<ipython-input-19-74f10773020b>:59] process_expend_file() enter, expend_s3_path:s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/47/system/item-data/expand/47.xlsx\n",
      "2021-03-17:09:01:53,676 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Movie\n",
      "2021-03-17:09:01:53,681 INFO     [<ipython-input-19-74f10773020b>:69] process_expend_file() return dataFrame, len: 4004\n",
      "2021-03-17:09:01:53,683 INFO     [<ipython-input-19-74f10773020b>:77] expand df columns=Index(['program_id', 'director', 'actor', 'popularity', 'ticket_num', 'score',\n",
      "       'level'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:53,684 INFO     [<ipython-input-19-74f10773020b>:59] process_expend_file() enter, expend_s3_path:s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/86/system/item-data/expand/86.xlsx\n",
      "2021-03-17:09:01:54,808 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: English Movie\n",
      "2021-03-17:09:01:54,811 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: New Movie\n",
      "2021-03-17:09:01:54,813 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Hot Movie\n",
      "2021-03-17:09:01:54,815 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Arabic Movie\n",
      "2021-03-17:09:01:54,817 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: VOD_Try\n",
      "2021-03-17:09:01:54,819 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: 3D Movie\n",
      "2021-03-17:09:01:54,821 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: French Movie\n",
      "2021-03-17:09:01:54,824 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Documentaries\n",
      "2021-03-17:09:01:54,826 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Portuguese Movie\n",
      "2021-03-17:09:01:54,828 INFO     [<ipython-input-19-74f10773020b>:65] now process sheet: Spain Movie\n",
      "2021-03-17:09:01:54,841 INFO     [<ipython-input-19-74f10773020b>:69] process_expend_file() return dataFrame, len: 3939\n",
      "2021-03-17:09:01:54,843 INFO     [<ipython-input-19-74f10773020b>:77] expand df columns=Index(['program_id', 'director', 'actor', 'popularity', 'ticket_num', 'score',\n",
      "       'level'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:54,865 INFO     [<ipython-input-19-74f10773020b>:82] process_basic_file() enter, process_basic_file:<function process_basic_file at 0x7fbae9a12c80>\n",
      "2021-03-17:09:01:54,971 INFO     [<ipython-input-19-74f10773020b>:84] basic df columns=Index(['program_id', 'program_type', 'program_name', 'sum_series',\n",
      "       'new_series', 'createtime', 'series_type', 'star_level', 'release_year',\n",
      "       'hdtv', 'play_level', 'category_property', 'language',\n",
      "       'original_country', 'description', 'picture_url', 'length',\n",
      "       'category_name'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:54,972 INFO     [<ipython-input-19-74f10773020b>:82] process_basic_file() enter, process_basic_file:<function process_basic_file at 0x7fbae9a12c80>\n",
      "2021-03-17:09:01:55,102 INFO     [<ipython-input-19-74f10773020b>:84] basic df columns=Index(['program_id', 'program_type', 'program_name', 'sum_series',\n",
      "       'new_series', 'createtime', 'series_type', 'star_level', 'release_year',\n",
      "       'hdtv', 'play_level', 'category_property', 'language',\n",
      "       'original_country', 'description', 'picture_url', 'length',\n",
      "       'category_name'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:55,103 INFO     [<ipython-input-19-74f10773020b>:82] process_basic_file() enter, process_basic_file:<function process_basic_file at 0x7fbae9a12c80>\n",
      "2021-03-17:09:01:55,245 INFO     [<ipython-input-19-74f10773020b>:84] basic df columns=Index(['program_id', 'program_type', 'program_name', 'sum_series',\n",
      "       'new_series', 'createtime', 'series_type', 'star_level', 'release_year',\n",
      "       'hdtv', 'play_level', 'category_property', 'language',\n",
      "       'original_country', 'description', 'picture_url', 'length',\n",
      "       'category_name'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:55,246 INFO     [<ipython-input-19-74f10773020b>:82] process_basic_file() enter, process_basic_file:<function process_basic_file at 0x7fbae9a12c80>\n",
      "2021-03-17:09:01:55,314 INFO     [<ipython-input-19-74f10773020b>:84] basic df columns=Index(['program_id', 'program_type', 'program_name', 'sum_series',\n",
      "       'new_series', 'createtime', 'series_type', 'star_level', 'release_year',\n",
      "       'hdtv', 'play_level', 'category_property', 'language',\n",
      "       'original_country', 'description', 'picture_url', 'length',\n",
      "       'category_name'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:55,314 INFO     [<ipython-input-19-74f10773020b>:82] process_basic_file() enter, process_basic_file:<function process_basic_file at 0x7fbae9a12c80>\n",
      "2021-03-17:09:01:55,392 INFO     [<ipython-input-19-74f10773020b>:84] basic df columns=Index(['program_id', 'program_type', 'program_name', 'sum_series',\n",
      "       'new_series', 'createtime', 'series_type', 'star_level', 'release_year',\n",
      "       'hdtv', 'play_level', 'category_property', 'language',\n",
      "       'original_country', 'description', 'picture_url', 'length',\n",
      "       'category_name'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:55,394 INFO     [<ipython-input-19-74f10773020b>:82] process_basic_file() enter, process_basic_file:<function process_basic_file at 0x7fbae9a12c80>\n",
      "2021-03-17:09:01:55,432 INFO     [<ipython-input-19-74f10773020b>:84] basic df columns=Index(['program_id', 'program_type', 'program_name', 'sum_series',\n",
      "       'new_series', 'createtime', 'series_type', 'star_level', 'release_year',\n",
      "       'hdtv', 'play_level', 'category_property', 'language',\n",
      "       'original_country', 'description', 'picture_url', 'length',\n",
      "       'category_name'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:55,433 INFO     [<ipython-input-19-74f10773020b>:82] process_basic_file() enter, process_basic_file:<function process_basic_file at 0x7fbae9a12c80>\n",
      "2021-03-17:09:01:55,511 INFO     [<ipython-input-19-74f10773020b>:84] basic df columns=Index(['program_id', 'program_type', 'program_name', 'sum_series',\n",
      "       'new_series', 'createtime', 'series_type', 'star_level', 'release_year',\n",
      "       'hdtv', 'play_level', 'category_property', 'language',\n",
      "       'original_country', 'description', 'picture_url', 'length',\n",
      "       'category_name'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:55,512 INFO     [<ipython-input-19-74f10773020b>:82] process_basic_file() enter, process_basic_file:<function process_basic_file at 0x7fbae9a12c80>\n",
      "2021-03-17:09:01:55,604 INFO     [<ipython-input-19-74f10773020b>:84] basic df columns=Index(['program_id', 'program_type', 'program_name', 'sum_series',\n",
      "       'new_series', 'createtime', 'series_type', 'star_level', 'release_year',\n",
      "       'hdtv', 'play_level', 'category_property', 'language',\n",
      "       'original_country', 'description', 'picture_url', 'length',\n",
      "       'category_name'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:55,605 INFO     [<ipython-input-19-74f10773020b>:82] process_basic_file() enter, process_basic_file:<function process_basic_file at 0x7fbae9a12c80>\n",
      "2021-03-17:09:01:55,924 INFO     [<ipython-input-19-74f10773020b>:84] basic df columns=Index(['program_id', 'program_type', 'program_name', 'sum_series',\n",
      "       'new_series', 'createtime', 'series_type', 'star_level', 'release_year',\n",
      "       'hdtv', 'play_level', 'category_property', 'language',\n",
      "       'original_country', 'description', 'picture_url', 'length',\n",
      "       'category_name'],\n",
      "      dtype='object')\n",
      "2021-03-17:09:01:56,8 INFO     [<ipython-input-19-74f10773020b>:96] df_merged len: 33767\n"
     ]
    }
   ],
   "source": [
    "basic_s3_path = basic_s3_files\n",
    "expend_s3_path = expend_s3_files\n",
    "logging.info(f\"gen_pick_files(), \"\n",
    "                 f\"\\nbasic_s3_path={basic_s3_path}, \"\n",
    "                 f\"\\nexpend_s3_path={expend_s3_path}, \"\n",
    "                 f\"\\nout_s3_path={out_s3_path}\")\n",
    "\n",
    "df = prepare_df(basic_s3_path, expend_s3_path)\n",
    "# dicts_1 = gen_movie_id_movie_property_dict(df)\n",
    "# dicts_2 = gen_movie_properties_to_movie_ids_dict(df)\n",
    "# dicts_all = dicts_1\n",
    "# dicts_all.update(dicts_2)\n",
    "# bucket, out_prefix = get_bucket_key_from_s3_path(out_s3_path)\n",
    "# for dict_name, dict_val in dicts_all.items():\n",
    "#     file_name = f'{dict_name}.pickle'\n",
    "#     # print(\"pickle =>\", file_name)\n",
    "#     out_file = open(file_name, 'wb')\n",
    "#     pickle.dump(dict_val, out_file)\n",
    "#     out_file.close()\n",
    "#     # s3_url = S3Uploader.upload(file_name, out_s3_path)\n",
    "#     s3_url = write_to_s3(file_name, bucket, f'{out_prefix}/{file_name}')\n",
    "#     logging.info(\"write {}\".format(s3_url))\n",
    "# logging.info(f\"generated {len(dicts_all)} pickle files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>program_id</th>\n",
       "      <th>program_type</th>\n",
       "      <th>program_name</th>\n",
       "      <th>sum_series</th>\n",
       "      <th>new_series</th>\n",
       "      <th>createtime</th>\n",
       "      <th>series_type</th>\n",
       "      <th>star_level</th>\n",
       "      <th>release_year</th>\n",
       "      <th>hdtv</th>\n",
       "      <th>...</th>\n",
       "      <th>description</th>\n",
       "      <th>picture_url</th>\n",
       "      <th>length</th>\n",
       "      <th>category_name</th>\n",
       "      <th>director</th>\n",
       "      <th>actor</th>\n",
       "      <th>popularity</th>\n",
       "      <th>ticket_num</th>\n",
       "      <th>score</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1689713</td>\n",
       "      <td>2</td>\n",
       "      <td>12 Hour Shift</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-10 06:19:37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Bodies start to pile up when a drug-user nurse...</td>\n",
       "      <td>photo/new_movie/12_hour_shift.jpg</td>\n",
       "      <td>86.0</td>\n",
       "      <td>New Movie</td>\n",
       "      <td>Brea Grant</td>\n",
       "      <td>['Angela Bettis', 'David Arquette', 'Chloe Far...</td>\n",
       "      <td>84.793</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1689714</td>\n",
       "      <td>2</td>\n",
       "      <td>12 Days Of Christmas</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-10 06:19:37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Childhood friends Amy and Steve come home from...</td>\n",
       "      <td>photo/new_movie/12_days_of_christmas.jpg</td>\n",
       "      <td>86.0</td>\n",
       "      <td>New Movie</td>\n",
       "      <td>Michael Boyle</td>\n",
       "      <td>['Annie Newton', 'Drew Petriello', 'Katee Shea...</td>\n",
       "      <td>4.330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1689715</td>\n",
       "      <td>2</td>\n",
       "      <td>American Utopia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-10 06:19:37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Spike Lee documents the former Talking Heads f...</td>\n",
       "      <td>photo/new_movie/american_utopia.jpg</td>\n",
       "      <td>135.0</td>\n",
       "      <td>New Movie</td>\n",
       "      <td>Spike Lee</td>\n",
       "      <td>['David Byrne', 'Chris Giarmo', 'Angie Swan', ...</td>\n",
       "      <td>8.748</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1689716</td>\n",
       "      <td>2</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-10 06:19:37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Young musician Zach Sobiech discovers his canc...</td>\n",
       "      <td>photo/new_movie/clouds.jpg</td>\n",
       "      <td>121.0</td>\n",
       "      <td>New Movie</td>\n",
       "      <td>Kara Holden</td>\n",
       "      <td>['Steffan Argus', 'Sabrina Carpenter', 'Madiso...</td>\n",
       "      <td>85.442</td>\n",
       "      <td>480.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>PG-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1689717</td>\n",
       "      <td>2</td>\n",
       "      <td>Cut Throat City</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-10 06:19:37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Set after Hurricane Katrina, four boyhood frie...</td>\n",
       "      <td>photo/new_movie/cut_throat_city.jpg</td>\n",
       "      <td>132.0</td>\n",
       "      <td>New Movie</td>\n",
       "      <td>RZA</td>\n",
       "      <td>['Terrence Howard', 'Wesley Snipes', 'T.I.', '...</td>\n",
       "      <td>261.266</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   program_id  program_type          program_name  sum_series  new_series  \\\n",
       "0     1689713             2         12 Hour Shift           1           1   \n",
       "1     1689714             2  12 Days Of Christmas           1           1   \n",
       "2     1689715             2       American Utopia           1           1   \n",
       "3     1689716             2                Clouds           1           1   \n",
       "4     1689717             2       Cut Throat City           1           1   \n",
       "\n",
       "            createtime  series_type  star_level release_year  hdtv  ...  \\\n",
       "0  2020-11-10 06:19:37            0           3         2020     0  ...   \n",
       "1  2020-11-10 06:19:37            0           3         2020     0  ...   \n",
       "2  2020-11-10 06:19:37            0           3         2020     0  ...   \n",
       "3  2020-11-10 06:19:37            0           3         2020     0  ...   \n",
       "4  2020-11-10 06:19:37            0           3         2020     0  ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Bodies start to pile up when a drug-user nurse...   \n",
       "1  Childhood friends Amy and Steve come home from...   \n",
       "2  Spike Lee documents the former Talking Heads f...   \n",
       "3  Young musician Zach Sobiech discovers his canc...   \n",
       "4  Set after Hurricane Katrina, four boyhood frie...   \n",
       "\n",
       "                                picture_url length category_name  \\\n",
       "0         photo/new_movie/12_hour_shift.jpg   86.0     New Movie   \n",
       "1  photo/new_movie/12_days_of_christmas.jpg   86.0     New Movie   \n",
       "2       photo/new_movie/american_utopia.jpg  135.0     New Movie   \n",
       "3                photo/new_movie/clouds.jpg  121.0     New Movie   \n",
       "4       photo/new_movie/cut_throat_city.jpg  132.0     New Movie   \n",
       "\n",
       "        director                                              actor  \\\n",
       "0     Brea Grant  ['Angela Bettis', 'David Arquette', 'Chloe Far...   \n",
       "1  Michael Boyle  ['Annie Newton', 'Drew Petriello', 'Katee Shea...   \n",
       "2      Spike Lee  ['David Byrne', 'Chris Giarmo', 'Angie Swan', ...   \n",
       "3    Kara Holden  ['Steffan Argus', 'Sabrina Carpenter', 'Madiso...   \n",
       "4            RZA  ['Terrence Howard', 'Wesley Snipes', 'T.I.', '...   \n",
       "\n",
       "   popularity ticket_num score  level  \n",
       "0      84.793       83.0   5.1    NaN  \n",
       "1       4.330        1.0   6.0     NR  \n",
       "2       8.748       15.0   7.8    NaN  \n",
       "3      85.442      480.0   8.5  PG-13  \n",
       "4     261.266       28.0   6.4     15  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_movie_id_movie_property_dict(df):\n",
    "    movie_id_movie_property_dict = {}\n",
    "    for row in df.iterrows():\n",
    "        item_row = row[1]\n",
    "        program_id = str(item_row['program_id'])\n",
    "        program_dict = {\n",
    "            'director': get_single_item(item_row['director']),\n",
    "            'level': get_single_item(item_row['level']),\n",
    "            'year': get_single_item(item_row['release_year']),\n",
    "            'actor': get_actor(item_row['actor']),\n",
    "            'category': get_category(item_row['category_property']),\n",
    "            'language': get_single_item(item_row['language'])\n",
    "        }\n",
    "        movie_id_movie_property_dict[program_id] = program_dict\n",
    "\n",
    "    result_dict = {\n",
    "        'movie_id_movie_property_dict': movie_id_movie_property_dict\n",
    "    }\n",
    "    return result_dict\n",
    "\n",
    "def item_embed(x, raw_embed_item_mapping, ub_item_embeddings):\n",
    "    embed_item_idx = raw_embed_item_mapping[str(x)]\n",
    "    if  int(embed_item_idx) < len(ub_item_embeddings):\n",
    "#         print(user_portrait[x])\n",
    "        return ub_item_embeddings[int(embed_item_idx)]\n",
    "    else:\n",
    "        return [0]*embed_dim\n",
    "    \n",
    "def item_id_feat(x, i):\n",
    "    return x[i]\n",
    "#     return pd.Series(f_dict)\n",
    "\n",
    "def sparse_item_id_feat(x, mt, dict_id_content=dict_id_content):\n",
    "    result = dict_id_content[str(x)][mt]\n",
    "    if result[0] is None:\n",
    "        return None\n",
    "    else:\n",
    "        return '|'.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_movie_property_dict = {}\n",
    "movie_id_movie_property_data = {}\n",
    "row_cnt = 0\n",
    "for row in df.iterrows():\n",
    "    item_row = row[1]\n",
    "    program_id = str(item_row['program_id'])\n",
    "    program_dict = {\n",
    "        'director': get_single_item(item_row['director']),\n",
    "        'level': get_single_item(item_row['level']),\n",
    "        'year': get_single_item(item_row['release_year']),\n",
    "        'actor': get_actor(item_row['actor']),\n",
    "        'category': get_category(item_row['category_property']),\n",
    "        'language': get_single_item(item_row['language'])\n",
    "    }\n",
    "    movie_id_movie_property_dict[program_id] = program_dict\n",
    "    row_content = []\n",
    "    row_content.append(str(item_row['program_id']))\n",
    "    row_content.append(program_dict['director'])\n",
    "    row_content.append(program_dict['level'])\n",
    "    row_content.append(program_dict['year'])\n",
    "    row_content.append(program_dict['actor'])\n",
    "    row_content.append(program_dict['category'])\n",
    "    row_content.append(program_dict['language'])\n",
    "    movie_id_movie_property_data['row_{}'.format(row_cnt)] = row_content \n",
    "    row_cnt = row_cnt + 1\n",
    "\n",
    "result_dict = {\n",
    "    'movie_id_movie_property_dict': movie_id_movie_property_dict\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1592446', ['julie prendiville roux'], ['pg-13'], ['2018'], ['briana evigan', 'garret dillahunt', 'charlie tahan', 'peggy sheffield', 'mary rachel dudley', 'tom nowicki'], ['drama', 'mystery'], ['korean']]\n"
     ]
    }
   ],
   "source": [
    "for k, v in movie_id_movie_property_data.items():\n",
    "    if v[0] ==  '1592446':\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>programId</th>\n",
       "      <th>director</th>\n",
       "      <th>level</th>\n",
       "      <th>year</th>\n",
       "      <th>actor</th>\n",
       "      <th>actegory</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1689713</td>\n",
       "      <td>[brea grant]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[2020]</td>\n",
       "      <td>[angela bettis, david arquette, chloe farnwort...</td>\n",
       "      <td>[comedy, horror, thriller]</td>\n",
       "      <td>[english]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1689714</td>\n",
       "      <td>[michael boyle]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[2020]</td>\n",
       "      <td>[annie newton, drew petriello, katee shean, sp...</td>\n",
       "      <td>[comedy, drama]</td>\n",
       "      <td>[english]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1689715</td>\n",
       "      <td>[spike lee]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[2020]</td>\n",
       "      <td>[david byrne, chris giarmo, angie swan, jacque...</td>\n",
       "      <td>[documentary, music, musical]</td>\n",
       "      <td>[english]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1689716</td>\n",
       "      <td>[kara holden]</td>\n",
       "      <td>[pg-13]</td>\n",
       "      <td>[2020]</td>\n",
       "      <td>[steffan argus, sabrina carpenter, madison ise...</td>\n",
       "      <td>[drama, music]</td>\n",
       "      <td>[english]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1689717</td>\n",
       "      <td>[rza]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[2020]</td>\n",
       "      <td>[terrence howard, wesley snipes, t.i., eiza go...</td>\n",
       "      <td>[action, crime, drama]</td>\n",
       "      <td>[english]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  programId         director    level    year  \\\n",
       "0   1689713     [brea grant]   [None]  [2020]   \n",
       "1   1689714  [michael boyle]   [None]  [2020]   \n",
       "2   1689715      [spike lee]   [None]  [2020]   \n",
       "3   1689716    [kara holden]  [pg-13]  [2020]   \n",
       "4   1689717            [rza]     [15]  [2020]   \n",
       "\n",
       "                                               actor  \\\n",
       "0  [angela bettis, david arquette, chloe farnwort...   \n",
       "1  [annie newton, drew petriello, katee shean, sp...   \n",
       "2  [david byrne, chris giarmo, angie swan, jacque...   \n",
       "3  [steffan argus, sabrina carpenter, madison ise...   \n",
       "4  [terrence howard, wesley snipes, t.i., eiza go...   \n",
       "\n",
       "                        actegory   language  \n",
       "0     [comedy, horror, thriller]  [english]  \n",
       "1                [comedy, drama]  [english]  \n",
       "2  [documentary, music, musical]  [english]  \n",
       "3                 [drama, music]  [english]  \n",
       "4         [action, crime, drama]  [english]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_pddf = pd.DataFrame.from_dict(movie_id_movie_property_data, orient='index', columns=['programId', 'director','level','year','actor','actegory','language'])\n",
    "raw_data_pddf = raw_data_pddf.reset_index(drop=True)\n",
    "raw_data_pddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  if sys.path[0] == '':\n",
      "2021-03-17:09:02:28,2 WARNING  [module_wrapper.py:139] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# deepfm模型训练逻辑\n",
    "# 基础依赖\n",
    "import argparse\n",
    "import pickle\n",
    "import boto3\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "# 模型相关\n",
    "from tensorflow.python.keras.models import Model, save_model, load_model\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat,get_feature_names\n",
    "from deepmatch.layers import custom_objects\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket=sagemaker-us-east-1-002224604296\n",
      "prefix='recommender-system-film-mk/1'\n",
      "file preparation: download src key recommender-system-film-mk/1/system/user-data/clean/latest/action.csv to dst key info/action.csv\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/action/raw_embed_item_mapping.pickle to dst key info/raw_embed_item_mapping.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/action/raw_embed_user_mapping.pickle to dst key info/raw_embed_user_mapping.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/action/ub_item_embeddings.npy to dst key info/ub_item_embeddings.npy\n",
      "file preparation: download src key recommender-system-film-mk/1/model/recall/youtubednn/user_embeddings.h5 to dst key info/user_embeddings.h5\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/content/inverted-list/movie_id_movie_property_dict.pickle to dst key info/movie_id_movie_property_dict.pickle\n",
      "load 207341 action data\n",
      "length of movie_id v.s. movie_property 33767\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# 从s3同步数据\n",
    "########################################\n",
    "def sync_s3(file_name_list, s3_folder, local_folder):\n",
    "    for f in file_name_list:\n",
    "        print(\"file preparation: download src key {} to dst key {}\".format(os.path.join(\n",
    "            s3_folder, f), os.path.join(local_folder, f)))\n",
    "        s3client.download_file(bucket, os.path.join(\n",
    "            s3_folder, f), os.path.join(local_folder, f))\n",
    "        \n",
    "def write_to_s3(filename, bucket, key):\n",
    "    with open(filename, 'rb') as f:  # Read in binary mode\n",
    "        return s3client.upload_fileobj(f, bucket, key)\n",
    "\n",
    "default_bucket = 'sagemaker-us-east-1-002224604296'\n",
    "default_mk_region = '1'\n",
    "level_1 = 'recommender-system-film-mk'\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--bucket', type=str, default=default_bucket)\n",
    "parser.add_argument('--mk-region', type=str, default=default_mk_region)\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "bucket = args.bucket\n",
    "mk_region = args.mk_region\n",
    "\n",
    "prefix = f\"{level_1}/{mk_region}\"\n",
    "\n",
    "print(\"bucket={}\".format(bucket))\n",
    "print(\"prefix='{}'\".format(prefix))\n",
    "\n",
    "s3client = boto3.client('s3')\n",
    "local_folder = 'info'\n",
    "if not os.path.exists(local_folder):\n",
    "    os.makedirs(local_folder)\n",
    "# 行为数据加载\n",
    "file_name_list = ['action.csv']\n",
    "s3_folder = '{}/system/user-data/clean/latest'.format(prefix)\n",
    "sync_s3(file_name_list, s3_folder, local_folder)\n",
    "# youtubednn模型数据加载\n",
    "file_name_list = ['raw_embed_item_mapping.pickle', 'raw_embed_user_mapping.pickle', 'ub_item_embeddings.npy']\n",
    "s3_folder = '{}/feature/action/'.format(prefix)\n",
    "sync_s3(file_name_list, s3_folder, local_folder)\n",
    "file_name_list = ['user_embeddings.h5']\n",
    "s3_folder = 'recommender-system-film-mk/1/model/recall/youtubednn/'\n",
    "sync_s3(file_name_list, s3_folder, local_folder)\n",
    "# 倒排列表的pickle文件\n",
    "file_name_list = ['movie_id_movie_property_dict.pickle']\n",
    "s3_folder = '{}/feature/content/inverted-list/'.format(prefix)\n",
    "sync_s3(file_name_list, s3_folder, local_folder)\n",
    "\n",
    "# 加载所有人的数据\n",
    "action_data_pddf = pd.read_csv(\"info/action.csv\", sep='\\t')\n",
    "print(\"load {} action data\".format(len(action_data_pddf)))\n",
    "# 加载pickle文件\n",
    "file_to_load = open(\"info/movie_id_movie_property_dict.pickle\", \"rb\")\n",
    "dict_id_content = pickle.load(file_to_load)\n",
    "print(\"length of movie_id v.s. movie_property {}\".format(len(dict_id_content)))\n",
    "file_to_load = open(\"info/raw_embed_item_mapping.pickle\", \"rb\")\n",
    "raw_embed_item_mapping = pickle.load(file_to_load)\n",
    "file_to_load = open(\"info/raw_embed_user_mapping.pickle\", \"rb\")\n",
    "raw_embed_user_mapping = pickle.load(file_to_load)\n",
    "# 加载模型\n",
    "# user_embedding_model = load_model('info/user_embeddings.h5', custom_objects)\n",
    "ub_item_embeddings = np.load(\"info/ub_item_embeddings.npy\")\n",
    "embed_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_pddf = raw_data_pddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成encoding的逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>userid</th>\n",
       "      <th>programId</th>\n",
       "      <th>programType</th>\n",
       "      <th>action</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13396</td>\n",
       "      <td>1690115</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1608198657</td>\n",
       "      <td>jungleland</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13396</td>\n",
       "      <td>1690115</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1608198696</td>\n",
       "      <td>jungleland</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>170811011119</td>\n",
       "      <td>1690115</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1610225454</td>\n",
       "      <td>jungleland</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>170811012694</td>\n",
       "      <td>1690115</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1612996593</td>\n",
       "      <td>jungleland</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24384</td>\n",
       "      <td>1690115</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1614031172</td>\n",
       "      <td>jungleland</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        userid  programId  programType  action   timeStamp  \\\n",
       "0      1         13396    1690115            1       2  1608198657   \n",
       "1      1         13396    1690115            1       2  1608198696   \n",
       "2      1  170811011119    1690115            1       2  1610225454   \n",
       "3      1  170811012694    1690115            1       2  1612996593   \n",
       "4      1         24384    1690115            1       2  1614031172   \n",
       "\n",
       "        title genres  \n",
       "0  jungleland  drama  \n",
       "1  jungleland  drama  \n",
       "2  jungleland  drama  \n",
       "3  jungleland  drama  \n",
       "4  jungleland  drama  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!!应该用用户注册数据来生成encoding map\n",
    "data_mk = pd.read_csv('info/action.csv',sep='\\t')\n",
    "data_mk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate lable encoding/ sparse feature\n",
    "lbe = LabelEncoder()\n",
    "sample_data_pddf['encode_id'] = lbe.fit_transform(sample_data_pddf['programId']) + 1\n",
    "data_mk['encode_id'] = lbe.fit_transform(data_mk['userid']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructu mapping dictionary\n",
    "raw_user_id_list = list(map(str,data_mk['userid'].values))\n",
    "code_user_id_list = list(map(int, data_mk['encode_id'].values))\n",
    "raw_embed_user_id_dict = dict(zip(raw_user_id_list, code_user_id_list))\n",
    "embed_raw_user_id_dict = dict(zip(code_user_id_list, raw_user_id_list))\n",
    "\n",
    "raw_item_id_list = list(map(str,sample_data_pddf['programId'].values))\n",
    "code_item_id_list = list(map(int, sample_data_pddf['encode_id'].values))\n",
    "raw_embed_item_id_dict = dict(zip(raw_item_id_list, code_item_id_list))\n",
    "embed_raw_item_id_dict = dict(zip(code_item_id_list, raw_item_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'info/raw_embed_user_mapping.pickle'\n",
    "output_file = open(file_name, 'wb')\n",
    "pickle.dump(raw_embed_user_id_dict, output_file)\n",
    "output_file.close()\n",
    "write_to_s3(file_name, bucket, \"{}/feature/action/{}\".format(prefix,file_name.split('/')[-1]))\n",
    "\n",
    "file_name = 'info/embed_raw_user_mapping.pickle'\n",
    "output_file = open(file_name, 'wb')\n",
    "pickle.dump(embed_raw_user_id_dict, output_file)\n",
    "output_file.close()\n",
    "write_to_s3(file_name, bucket, \"{}/feature/action/{}\".format(prefix,file_name.split('/')[-1]))\n",
    "\n",
    "file_name = 'info/raw_embed_item_mapping.pickle'\n",
    "output_file = open(file_name, 'wb')\n",
    "pickle.dump(raw_embed_item_id_dict, output_file)\n",
    "output_file.close()\n",
    "write_to_s3(file_name, bucket, \"{}/feature/action/{}\".format(prefix,file_name.split('/')[-1]))\n",
    "\n",
    "file_name = 'info/embed_raw_item_mapping.pickle'\n",
    "output_file = open(file_name, 'wb')\n",
    "pickle.dump(embed_raw_item_id_dict, output_file)\n",
    "output_file.close()\n",
    "write_to_s3(file_name, bucket, \"{}/feature/action/{}\".format(prefix,file_name.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备item feature的逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_pddf = raw_data_pddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据item_id索引itemid_feat（嵌入）\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f104a20b9534e68a297bae4b90d67e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=33767.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "将32维物品嵌入转化为不同的连续型feature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 53.62it/s]\n",
      "3it [00:00, 25.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据item_id对应的content生成离散feature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 25.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# item id feature - item embedding\n",
    "print(\"根据item_id索引itemid_feat（嵌入）\")\n",
    "sample_data_pddf['itemid_feat'] = sample_data_pddf['programId'].progress_apply(lambda x: item_embed(x, raw_embed_item_mapping, ub_item_embeddings))\n",
    "print(\"将{}维物品嵌入转化为不同的连续型feature\".format(embed_dim))\n",
    "for i in tqdm(range(embed_dim)):\n",
    "    sample_data_pddf['item_feature_{}'.format(i)] = sample_data_pddf['itemid_feat'].apply(lambda x: item_id_feat(x, i))\n",
    "# sparse feature\n",
    "print(\"根据item_id对应的content生成离散feature\")\n",
    "popularity_method_list = ['category', 'director',\n",
    "                          'actor', 'language', 'level', 'year']\n",
    "for i, mt in tqdm(enumerate(popularity_method_list)):\n",
    "    sample_data_pddf['sparse_feature_{}'.format(i)] = sample_data_pddf['programId'].apply(lambda x: sparse_item_id_feat(x, mt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_data = sample_data_pddf\n",
    "dense_feature_size = embed_dim\n",
    "sparse_feature_size = 6\n",
    "for i in range(dense_feature_size):\n",
    "    mk_data['I{}'.format(i+embed_dim)] = mk_data['item_feature_{}'.format(i)]\n",
    "for i in range(sparse_feature_size):\n",
    "    mk_data['C{}'.format(i+1)] = mk_data['sparse_feature_{}'.format(i)]\n",
    "    \n",
    "mk_sparse_features = ['C' + str(i)for i in range(1, sparse_feature_size+1)]\n",
    "mk_dense_features = ['I'+str(i+embed_dim-1) for i in range(1, dense_feature_size+1)]\n",
    "mk_data[mk_sparse_features] = mk_data[mk_sparse_features].fillna('-1', )\n",
    "mk_data[mk_dense_features] = mk_data[mk_dense_features].fillna(0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in mk_sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    mk_data[feat] = lbe.fit_transform(mk_data[feat])\n",
    "nms = MinMaxScaler(feature_range=(0,1))\n",
    "mk_data[mk_dense_features] = nms.fit_transform(mk_data[mk_dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>programId</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>I32</th>\n",
       "      <th>I33</th>\n",
       "      <th>I34</th>\n",
       "      <th>...</th>\n",
       "      <th>I55</th>\n",
       "      <th>I56</th>\n",
       "      <th>I57</th>\n",
       "      <th>I58</th>\n",
       "      <th>I59</th>\n",
       "      <th>I60</th>\n",
       "      <th>I61</th>\n",
       "      <th>I62</th>\n",
       "      <th>I63</th>\n",
       "      <th>item_feat_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1689713</td>\n",
       "      <td>488</td>\n",
       "      <td>506</td>\n",
       "      <td>303</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0.606309</td>\n",
       "      <td>0.369546</td>\n",
       "      <td>0.318244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585189</td>\n",
       "      <td>0.663026</td>\n",
       "      <td>0.563234</td>\n",
       "      <td>0.389655</td>\n",
       "      <td>0.576787</td>\n",
       "      <td>0.592338</td>\n",
       "      <td>0.638990</td>\n",
       "      <td>0.669460</td>\n",
       "      <td>0.638478</td>\n",
       "      <td>0.519118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1689714</td>\n",
       "      <td>444</td>\n",
       "      <td>2909</td>\n",
       "      <td>355</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0.517393</td>\n",
       "      <td>0.199965</td>\n",
       "      <td>0.423809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426267</td>\n",
       "      <td>0.552058</td>\n",
       "      <td>0.475349</td>\n",
       "      <td>0.473056</td>\n",
       "      <td>0.446144</td>\n",
       "      <td>0.718610</td>\n",
       "      <td>0.466241</td>\n",
       "      <td>0.774546</td>\n",
       "      <td>0.464693</td>\n",
       "      <td>0.470722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1689715</td>\n",
       "      <td>591</td>\n",
       "      <td>3894</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0.389094</td>\n",
       "      <td>0.185065</td>\n",
       "      <td>0.515736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308511</td>\n",
       "      <td>0.556993</td>\n",
       "      <td>0.429952</td>\n",
       "      <td>0.367128</td>\n",
       "      <td>0.524741</td>\n",
       "      <td>0.857228</td>\n",
       "      <td>0.365313</td>\n",
       "      <td>0.498664</td>\n",
       "      <td>0.303065</td>\n",
       "      <td>0.536152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1689716</td>\n",
       "      <td>652</td>\n",
       "      <td>2336</td>\n",
       "      <td>4582</td>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "      <td>146</td>\n",
       "      <td>0.606364</td>\n",
       "      <td>0.369539</td>\n",
       "      <td>0.315198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586647</td>\n",
       "      <td>0.665346</td>\n",
       "      <td>0.561612</td>\n",
       "      <td>0.390187</td>\n",
       "      <td>0.577560</td>\n",
       "      <td>0.591738</td>\n",
       "      <td>0.638981</td>\n",
       "      <td>0.672033</td>\n",
       "      <td>0.638829</td>\n",
       "      <td>0.519078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1689717</td>\n",
       "      <td>111</td>\n",
       "      <td>3688</td>\n",
       "      <td>4761</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>146</td>\n",
       "      <td>0.415875</td>\n",
       "      <td>0.259687</td>\n",
       "      <td>0.318870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736896</td>\n",
       "      <td>0.632151</td>\n",
       "      <td>0.449616</td>\n",
       "      <td>0.490006</td>\n",
       "      <td>0.493057</td>\n",
       "      <td>0.712044</td>\n",
       "      <td>0.706084</td>\n",
       "      <td>0.618382</td>\n",
       "      <td>0.540678</td>\n",
       "      <td>0.520524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  programId   C1    C2    C3  C4  C5   C6       I32       I33       I34  ...  \\\n",
       "0   1689713  488   506   303   5   0  146  0.606309  0.369546  0.318244  ...   \n",
       "1   1689714  444  2909   355   5   0  146  0.517393  0.199965  0.423809  ...   \n",
       "2   1689715  591  3894  1193   5   0  146  0.389094  0.185065  0.515736  ...   \n",
       "3   1689716  652  2336  4582   5  65  146  0.606364  0.369539  0.315198  ...   \n",
       "4   1689717  111  3688  4761   5  17  146  0.415875  0.259687  0.318870  ...   \n",
       "\n",
       "        I55       I56       I57       I58       I59       I60       I61  \\\n",
       "0  0.585189  0.663026  0.563234  0.389655  0.576787  0.592338  0.638990   \n",
       "1  0.426267  0.552058  0.475349  0.473056  0.446144  0.718610  0.466241   \n",
       "2  0.308511  0.556993  0.429952  0.367128  0.524741  0.857228  0.365313   \n",
       "3  0.586647  0.665346  0.561612  0.390187  0.577560  0.591738  0.638981   \n",
       "4  0.736896  0.632151  0.449616  0.490006  0.493057  0.712044  0.706084   \n",
       "\n",
       "        I62       I63  item_feat_mean  \n",
       "0  0.669460  0.638478        0.519118  \n",
       "1  0.774546  0.464693        0.470722  \n",
       "2  0.498664  0.303065        0.536152  \n",
       "3  0.672033  0.638829        0.519078  \n",
       "4  0.618382  0.540678        0.520524  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_id_movie_feature_data = {}\n",
    "for row in mk_data.iterrows():\n",
    "    item_row = row[1]\n",
    "#     print(item_row)\n",
    "#     break\n",
    "    program_dict = str(item_row['programId'])\n",
    "    row_content = []\n",
    "    row_content.append(str(item_row['programId']))\n",
    "    dense_score = []\n",
    "    for feat in mk_sparse_features:\n",
    "        row_content.append(item_row[feat])\n",
    "    for feat in mk_dense_features:\n",
    "        row_content.append(item_row[feat])\n",
    "        dense_score.append(item_row[feat])\n",
    "    row_content.append(np.mean(dense_score))\n",
    "    movie_id_movie_feature_data['row_{}'.format(row_cnt)] = row_content \n",
    "    row_cnt = row_cnt + 1\n",
    "\n",
    "col_names = ['programId'] + mk_sparse_features + mk_dense_features + ['item_feat_mean']\n",
    "mk_item_feature_pddf = pd.DataFrame.from_dict(movie_id_movie_feature_data, orient='index', columns=col_names)\n",
    "mk_item_feature_pddf = mk_item_feature_pddf.reset_index(drop=True)\n",
    "mk_item_feature_pddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'info/movie_id_movie_feature_dict.pickle'\n",
    "mk_item_feature_pddf.to_pickle(file_name)\n",
    "write_to_s3(file_name, bucket, \"{}/feature/content/inverted-list/{}\".format(prefix,file_name.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pdf = pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_pdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-82cd4d698333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_pdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_pdf' is not defined"
     ]
    }
   ],
   "source": [
    "test_pdf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
