{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "import boto3\n",
    "import faiss\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from random import sample\n",
    "########################################\n",
    "# 从s3同步数据\n",
    "########################################\n",
    "def sync_s3(file_name_list, s3_folder, local_folder):\n",
    "    for f in file_name_list:\n",
    "        print(\"file preparation: download src key {} to dst key {}\".format(os.path.join(\n",
    "            s3_folder, f), os.path.join(local_folder, f)))\n",
    "        s3client.download_file(bucket, os.path.join(\n",
    "            s3_folder, f), os.path.join(local_folder, f))\n",
    "\n",
    "\n",
    "default_bucket = 'sagemaker-us-east-1-002224604296'\n",
    "default_mk_region = '1'\n",
    "level_1 = 'recommender-system-film-mk'\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--bucket', type=str, default=default_bucket)\n",
    "# parser.add_argument('--mk-region', type=str, default=default_mk_region)\n",
    "\n",
    "# args, _ = parser.parse_known_args()\n",
    "bucket = default_bucket\n",
    "mk_region = default_mk_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket=sagemaker-us-east-1-002224604296\n",
      "prefix='recommender-system-film-mk/1'\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/recommend-list/movie/recall_batch_result.pickle to dst key info/recall_batch_result.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/recommend-list/movie/rank_batch_result.pickle to dst key info/rank_batch_result.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/recommend-list/portrait/portrait.pickle to dst key info/portrait.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/content/inverted-list/movie_id_movie_property_dict.pickle to dst key info/movie_id_movie_property_dict.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/content/inverted-list/movie_category_movie_ids_dict.pickle to dst key info/movie_category_movie_ids_dict.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/content/inverted-list/movie_director_movie_ids_dict.pickle to dst key info/movie_director_movie_ids_dict.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/content/inverted-list/movie_actor_movie_ids_dict.pickle to dst key info/movie_actor_movie_ids_dict.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/content/inverted-list/movie_language_movie_ids_dict.pickle to dst key info/movie_language_movie_ids_dict.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/content/inverted-list/movie_level_movie_ids_dict.pickle to dst key info/movie_level_movie_ids_dict.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/content/inverted-list/movie_year_movie_ids_dict.pickle to dst key info/movie_year_movie_ids_dict.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/model/filter/filter_config.pickle to dst key info/filter_config.pickle\n",
      "length of movie_id v.s. movie_property 33767\n",
      "length of movie_category v.s. movie_ids 91\n",
      "length of movie_dicrector v.s. movie_ids 4468\n",
      "length of movie_actor v.s. movie_ids 26011\n",
      "length of movie_lanugage v.s. movie_ids 18\n",
      "length of movie_level v.s. movie_ids 84\n",
      "length of movie_year v.s. movie_ids 148\n",
      "length of user_portrait 1802\n",
      "length of filter_config 2\n"
     ]
    }
   ],
   "source": [
    "prefix = f\"{level_1}/{mk_region}\"\n",
    "\n",
    "print(\"bucket={}\".format(bucket))\n",
    "print(\"prefix='{}'\".format(prefix))\n",
    "\n",
    "s3client = boto3.client('s3')\n",
    "local_folder = 'info'\n",
    "if not os.path.exists(local_folder):\n",
    "    os.makedirs(local_folder)\n",
    "# recall & rank 结果加载\n",
    "file_name_list = ['recall_batch_result.pickle','rank_batch_result.pickle']\n",
    "s3_folder = '{}/feature/recommend-list/movie'.format(prefix)\n",
    "sync_s3(file_name_list, s3_folder, local_folder)\n",
    "# 用户画像数据加载\n",
    "file_name_list = ['portrait.pickle']\n",
    "s3_folder = '{}/feature/recommend-list/portrait'.format(prefix)\n",
    "sync_s3(file_name_list, s3_folder, local_folder)\n",
    "# 倒排列表的pickle文件\n",
    "file_name_list = ['movie_id_movie_property_dict.pickle',\n",
    "                  'movie_category_movie_ids_dict.pickle',\n",
    "                  'movie_director_movie_ids_dict.pickle',\n",
    "                  'movie_actor_movie_ids_dict.pickle',\n",
    "                  'movie_language_movie_ids_dict.pickle',\n",
    "                  'movie_level_movie_ids_dict.pickle',\n",
    "                  'movie_year_movie_ids_dict.pickle']\n",
    "s3_folder = '{}/feature/content/inverted-list/'.format(prefix)\n",
    "sync_s3(file_name_list, s3_folder, local_folder)\n",
    "# filter配置项\n",
    "file_name_list = ['filter_config.pickle']\n",
    "s3_folder = '{}/model/filter/'.format(prefix)\n",
    "sync_s3(file_name_list, s3_folder, local_folder)\n",
    "\n",
    "# 加载pickle文件\n",
    "file_to_load = open(\"info/movie_id_movie_property_dict.pickle\", \"rb\")\n",
    "dict_id_content = pickle.load(file_to_load)\n",
    "print(\"length of movie_id v.s. movie_property {}\".format(len(dict_id_content)))\n",
    "\n",
    "file_to_load = open(\"info/movie_category_movie_ids_dict.pickle\", \"rb\")\n",
    "dict_category_id = pickle.load(file_to_load)\n",
    "print(\"length of movie_category v.s. movie_ids {}\".format(len(dict_category_id)))\n",
    "\n",
    "file_to_load = open(\"info/movie_director_movie_ids_dict.pickle\", \"rb\")\n",
    "dict_director_id = pickle.load(file_to_load)\n",
    "print(\"length of movie_dicrector v.s. movie_ids {}\".format(len(dict_director_id)))\n",
    "\n",
    "file_to_load = open(\"info/movie_actor_movie_ids_dict.pickle\", \"rb\")\n",
    "dict_actor_id = pickle.load(file_to_load)\n",
    "print(\"length of movie_actor v.s. movie_ids {}\".format(len(dict_actor_id)))\n",
    "\n",
    "file_to_load = open(\"info/movie_language_movie_ids_dict.pickle\", \"rb\")\n",
    "dict_language_id = pickle.load(file_to_load)\n",
    "print(\"length of movie_lanugage v.s. movie_ids {}\".format(len(dict_language_id)))\n",
    "\n",
    "file_to_load = open(\"info/movie_level_movie_ids_dict.pickle\", \"rb\")\n",
    "dict_level_id = pickle.load(file_to_load)\n",
    "print(\"length of movie_level v.s. movie_ids {}\".format(len(dict_level_id)))\n",
    "\n",
    "file_to_load = open(\"info/movie_year_movie_ids_dict.pickle\", \"rb\")\n",
    "dict_year_id = pickle.load(file_to_load)\n",
    "print(\"length of movie_year v.s. movie_ids {}\".format(len(dict_year_id)))\n",
    "\n",
    "file_to_load = open(\"info/portrait.pickle\", \"rb\")\n",
    "user_portrait = pickle.load(file_to_load)\n",
    "print(\"length of user_portrait {}\".format(len(user_portrait)))\n",
    "\n",
    "# 加载filter配置\n",
    "file_to_load = open(\"info/filter_config.pickle\", \"rb\")\n",
    "filter_config = pickle.load(file_to_load)\n",
    "print(\"length of filter_config {}\".format(len(filter_config)))\n",
    "\n",
    "# 加载recall结果\n",
    "file_to_load = open(\"info/recall_batch_result.pickle\", \"rb\")\n",
    "dict_recall_result = pickle.load(file_to_load)\n",
    "\n",
    "# 加载rank结果\n",
    "file_to_load = open(\"info/rank_batch_result.pickle\", \"rb\")\n",
    "dict_rank_result = pickle.load(file_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回结果格式设计：\n",
    "# item_id | recall_type | recall_score | rank_type | rank_score | filter_type | filter_score\n",
    "\n",
    "# recall_type: [运行时机]_[方法]_[位置]\n",
    "# [运行时机]: batch/online\n",
    "# [方法]: category/director/actor/language/level/year/review/photo/ub/portrai_xxx\n",
    "# [位置]: 数字[0-xxx]\n",
    "\n",
    "# recall_score: 召回得分，float型\n",
    "\n",
    "# rank_type: [运行时机]_[方法]_[位置]\n",
    "# [运行时机]: batch/online\n",
    "# [数据源头]: action/portrait\n",
    "# [方法]: deepfm/xgboost\n",
    "# [位置]: 数字[0-xxx]\n",
    "\n",
    "# rank_score: 排序得分，float型\n",
    "\n",
    "# filter_type: [运行时机]_[方法]_[位置]\n",
    "# [运行时机]: batch/online\n",
    "# [方法]: recommend/coldstart/disparity\n",
    "# [位置]: 数字[0-xxx]\n",
    "\n",
    "# filter_score: 过滤得分，float型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_pos(key, dict_var):\n",
    "    return list(dict_var.keys()).index(key)\n",
    "def calc_filter_score(recall_score, rank_score, recall_mt=None, rank_mt=None, recall_pos=None, rank_pos=None):\n",
    "    filter_score = min(1.0, recall_score/40.0 + rank_score)\n",
    "    return round(filter_score,2)\n",
    "def mt_construct(timing, mt, pos):\n",
    "    type_list = []\n",
    "    type_list.append(str(timing))\n",
    "    type_list.append(str(mt))\n",
    "    type_list.append(str(pos))\n",
    "    type_name = '_'.join(type_list)\n",
    "    return type_name\n",
    "def sort_and_fill_pos(filter_result):\n",
    "    sort_filter_result = dict(\n",
    "            sorted(filter_result.items(), key=lambda item: item[1][2], reverse=True))\n",
    "    filter_pos = 0\n",
    "    update_filter_result = dict()\n",
    "    for filter_id, filter_content in sort_filter_result.items():\n",
    "        current_trace = filter_content[3]\n",
    "        current_trace_split_list = current_trace.split('|')\n",
    "        current_filter_type = current_trace_split_list[4]\n",
    "        current_filter_type_split_list = current_filter_type.split('_')\n",
    "        update_filter_type_split_list = current_filter_type_split_list\n",
    "        update_filter_type_split_list[2] = str(filter_pos)\n",
    "        update_filter_type = '_'.join(update_filter_type_split_list)\n",
    "        update_trace_split_list = current_trace_split_list\n",
    "        update_trace_split_list[-2] = update_filter_type\n",
    "        update_trace = '|' .join(update_trace_split_list)\n",
    "        update_filter_content = filter_content\n",
    "        update_filter_content[3] = update_trace\n",
    "#         print(\"update id {} trace {} type {}\".format(filter_id, update_trace,update_filter_type_split_list))\n",
    "        update_filter_result[str(filter_id)] = update_filter_content\n",
    "        # update filter pos\n",
    "        filter_pos = filter_pos + 1\n",
    "        \n",
    "def initial_diversity(stats_result, filter_config):\n",
    "    for cate in filter_config['category']:\n",
    "        stats_result[cate] = 0\n",
    "    \n",
    "def category_diversity_logic(filter_result, stats_result, dict_category_id, filter_config):\n",
    "    diversity_count = filter_config['category_diversity_count']\n",
    "    min_category = None\n",
    "    min_category_count = 999\n",
    "    candidate_category_list = []\n",
    "    for cate, count in stats_result.items():\n",
    "        if count < min_category_count and count != 0:\n",
    "            min_category_count = count\n",
    "            min_category = cate\n",
    "        elif count == 0:\n",
    "            candidate_category_list.append(cate)\n",
    "    if min_category != None:\n",
    "        candidate_category_list.append(min_category)\n",
    "    diversity_result_list = []\n",
    "    diversity_result_content_list= []\n",
    "    current_diversity_count = 0\n",
    "    \n",
    "    filter_result_list = list(filter_result.keys())\n",
    "    filter_result_content_list = list(filter_result.values())\n",
    "    sample_try = 0\n",
    "    catch_count = 0\n",
    "    while catch_count < diversity_count:\n",
    "        for cate in candidate_category_list:\n",
    "            sample_try = sample_try + 1\n",
    "            candidate_id = sample(dict_category_id[str(cate)],1)\n",
    "            if candidate_id in filter_result_list:\n",
    "                continue\n",
    "            else:\n",
    "                filter_result_list.append(str(candidate_id))\n",
    "                filter_result_content_list.append([str(candidate_id), 'diversity', 0.0, 'batch_diversity_{}|{}'.format(len(filter_result_list),cate)])\n",
    "                catch_count = catch_count + 1\n",
    "                if catch_count >= diversity_count:\n",
    "                    break\n",
    "        if sample_try > 5*diversity_count:\n",
    "            logging.error(\"fail to find enough diversity candidate, need to find {} but only find {}\".format(diversity_count, catch_count+1))\n",
    "            break\n",
    "        \n",
    "    update_filter_result = dict(zip(filter_result_list, filter_result_content_list))\n",
    "    return update_filter_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同一批次去重/统计\n",
    "# 运行时机\n",
    "run_timing = 'batch'\n",
    "dict_filter_result = {}\n",
    "for user_id, recall_result in dict_recall_result.items():\n",
    "#     print(\"user id {}\".format(user_id))\n",
    "    current_user_result = {}\n",
    "    current_diversity_result = {}\n",
    "    initial_diversity(current_diversity_result, filter_config)\n",
    "    for recall_id, recall_property in recall_result.items():\n",
    "#         print(\"item id {} recall_property {}\".format(recall_id, recall_property))\n",
    "        # 构建recall_type\n",
    "        recall_type = mt_construct(run_timing, recall_property[1], recall_property[2])\n",
    "        # 构建recall_score\n",
    "        recall_score = round(recall_property[3],2)\n",
    "        # 构建rank_type\n",
    "        rank_pos = str(get_dict_pos(int(recall_id), dict_rank_result[str(user_id)]))\n",
    "        rank_type = mt_construct(run_timing, 'deepfm', rank_pos)\n",
    "        # 构建rank_score\n",
    "        rank_score = round(dict_rank_result[str(user_id)][int(recall_id)],2)\n",
    "        # 构建filter_type\n",
    "        filter_type = mt_construct(run_timing, 'recommend', 'TBD')\n",
    "        # 构建filter_score\n",
    "        filter_score = calc_filter_score(recall_score, rank_score)\n",
    "#         print(\"{}|{}|{}|{}|{}|{}\".format(recall_type,recall_score,rank_type,rank_score))\n",
    "#         break\n",
    "        recommend_trace = \"{}|{}|{}|{}|{}|{}\".format(recall_type,recall_score,rank_type,rank_score,filter_type,filter_score)\n",
    "        current_user_result[str(recall_id)]=[]\n",
    "        current_user_result[str(recall_id)].append(str(recall_id))\n",
    "        current_user_result[str(recall_id)].append('recommend')\n",
    "        current_user_result[str(recall_id)].append(filter_score)\n",
    "        current_user_result[str(recall_id)].append(recommend_trace)\n",
    "        # 更新多样性统计\n",
    "        current_category = dict_id_content[str(recall_id)]['category']\n",
    "        for cate in current_category:\n",
    "            if cate is not None:\n",
    "                current_diversity_result[cate] = current_diversity_result[cate] + 1\n",
    "    # 根据filter score更新排序\n",
    "    sort_and_fill_pos(current_user_result)\n",
    "    update_user_result = category_diversity_logic(current_user_result, current_diversity_result, dict_category_id, filter_config)\n",
    "    dict_filter_result[str(user_id)] = update_user_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_config = {}\n",
    "filter_config['category'] = list(dict_category_id.keys())\n",
    "filter_config['category_diversity_count'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1.5 KiB/1.5 KiB (14.0 KiB/s) with 1 file(s) remaining\r",
      "upload: info/filter_config.pickle to s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1/model/filter/filter_config.pickle\r\n"
     ]
    }
   ],
   "source": [
    "file_name = 'info/filter_config.pickle'\n",
    "output_file = open(file_name, 'wb')\n",
    "pickle.dump(filter_config, output_file)\n",
    "output_file.close()\n",
    "\n",
    "!aws s3 cp info/filter_config.pickle s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1/model/filter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for k,v in dict_filter_result.items():\n",
    "    print(\"key {} and value {}\".format(k,v))\n",
    "    if n > 2:\n",
    "        break\n",
    "    n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for k,v in dict_rank_result.items():\n",
    "    print(\"key {} and value {}\".format(k,v))\n",
    "    if n > 2:\n",
    "        break\n",
    "    n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket=sagemaker-us-east-1-002224604296\n",
      "prefix='recommender-system-film-mk/1'\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/recommend-list/movie/recall_batch_result.pickle to dst key info/recall_batch_result.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/recommend-list/movie/rank_batch_result.pickle to dst key info/rank_batch_result.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/content/inverted-list/movie_id_movie_property_dict.pickle to dst key info/movie_id_movie_property_dict.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/content/inverted-list/movie_category_movie_ids_dict.pickle to dst key info/movie_category_movie_ids_dict.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/model/filter/filter_config.pickle to dst key info/filter_config.pickle\n",
      "length of movie_id v.s. movie_property 33767\n",
      "length of movie_category v.s. movie_ids 91\n",
      "length of filter_config 2\n",
      "upload s3://sagemaker-us-east-1-002224604296/recommender-system-film-mk/1/feature/recommend-list/movie/filter_batch_result.pickle\n"
     ]
    }
   ],
   "source": [
    "!python filter-batch.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
