{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘info/*’: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm info/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# youtubednn嵌入部分模型训练逻辑\n",
    "# 基础依赖\n",
    "import argparse\n",
    "import pickle\n",
    "import boto3\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "# 模型相关\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat\n",
    "from preprocess import gen_data_set, gen_model_input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model, save_model, load_model\n",
    "import faiss\n",
    "from deepmatch.models import *\n",
    "from deepmatch.utils import sampledsoftmaxloss\n",
    "from deepmatch.utils import recall_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket=sagemaker-us-east-1-002224604296\n",
      "prefix='recommender-system-film-mk/1'\n",
      "file preparation: download src key recommender-system-film-mk/1/system/user-data/clean/latest/action.csv to dst key info/action.csv\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/action/raw_embed_item_mapping.pickle to dst key info/raw_embed_item_mapping.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/action/raw_embed_user_mapping.pickle to dst key info/raw_embed_user_mapping.pickle\n",
      "load 207341 action data\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# 从s3同步数据\n",
    "########################################\n",
    "def sync_s3(file_name_list, s3_folder, local_folder):\n",
    "    for f in file_name_list:\n",
    "        print(\"file preparation: download src key {} to dst key {}\".format(os.path.join(\n",
    "            s3_folder, f), os.path.join(local_folder, f)))\n",
    "        s3client.download_file(bucket, os.path.join(\n",
    "            s3_folder, f), os.path.join(local_folder, f))\n",
    "        \n",
    "def write_to_s3(filename, bucket, key):\n",
    "    with open(filename, 'rb') as f:  # Read in binary mode\n",
    "        return s3client.upload_fileobj(f, bucket, key)\n",
    "\n",
    "default_bucket = 'sagemaker-us-east-1-002224604296'\n",
    "default_mk_region = '1'\n",
    "level_1 = 'recommender-system-film-mk'\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--bucket', type=str, default=default_bucket)\n",
    "parser.add_argument('--mk-region', type=str, default=default_mk_region)\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "bucket = args.bucket\n",
    "mk_region = args.mk_region\n",
    "\n",
    "prefix = f\"{level_1}/{mk_region}\"\n",
    "\n",
    "print(\"bucket={}\".format(bucket))\n",
    "print(\"prefix='{}'\".format(prefix))\n",
    "\n",
    "s3client = boto3.client('s3')\n",
    "local_folder = 'info'\n",
    "if not os.path.exists(local_folder):\n",
    "    os.makedirs(local_folder)\n",
    "# 行为数据加载\n",
    "file_name_list = ['action.csv']\n",
    "s3_folder = '{}/system/user-data/clean/latest'.format(prefix)\n",
    "sync_s3(file_name_list, s3_folder, local_folder)\n",
    "# encode映射数据\n",
    "file_name_list = ['raw_embed_item_mapping.pickle', 'raw_embed_user_mapping.pickle']\n",
    "s3_folder = '{}/feature/action/'.format(prefix)\n",
    "sync_s3(file_name_list, s3_folder, local_folder)\n",
    "# 加载pickle文件\n",
    "file_to_load = open(\"info/raw_embed_item_mapping.pickle\", \"rb\")\n",
    "raw_embed_item_mapping = pickle.load(file_to_load)\n",
    "file_to_load = open(\"info/raw_embed_user_mapping.pickle\", \"rb\")\n",
    "raw_embed_user_mapping = pickle.load(file_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>userid</th>\n",
       "      <th>programId</th>\n",
       "      <th>programType</th>\n",
       "      <th>action</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6714</th>\n",
       "      <td>1</td>\n",
       "      <td>h50e7e4eb0891</td>\n",
       "      <td>1681277</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1613782683</td>\n",
       "      <td>becoming</td>\n",
       "      <td>documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7241</th>\n",
       "      <td>1</td>\n",
       "      <td>h50e7e4eb0891</td>\n",
       "      <td>1681277</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1613782674</td>\n",
       "      <td>becoming</td>\n",
       "      <td>documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17784</th>\n",
       "      <td>0</td>\n",
       "      <td>h50e7e4eb0891</td>\n",
       "      <td>1681278</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1613782664</td>\n",
       "      <td>father soldier son</td>\n",
       "      <td>documentary|war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27107</th>\n",
       "      <td>0</td>\n",
       "      <td>h50e7e4eb0891</td>\n",
       "      <td>1647202</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1613782664</td>\n",
       "      <td>game of thrones s08e06</td>\n",
       "      <td>action|adventure|drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83744</th>\n",
       "      <td>0</td>\n",
       "      <td>h50e7e4eb0891</td>\n",
       "      <td>1676922</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1613782664</td>\n",
       "      <td>les plus belles annees dune vie</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109462</th>\n",
       "      <td>0</td>\n",
       "      <td>h50e7e4eb0891</td>\n",
       "      <td>1692202</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1613782676</td>\n",
       "      <td>15 august</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label         userid  programId  programType  action   timeStamp  \\\n",
       "6714        1  h50e7e4eb0891    1681277            1       2  1613782683   \n",
       "7241        1  h50e7e4eb0891    1681277            1       1  1613782674   \n",
       "17784       0  h50e7e4eb0891    1681278            1       1  1613782664   \n",
       "27107       0  h50e7e4eb0891    1647202            1       1  1613782664   \n",
       "83744       0  h50e7e4eb0891    1676922            1       1  1613782664   \n",
       "109462      0  h50e7e4eb0891    1692202            1       1  1613782676   \n",
       "\n",
       "                                  title                  genres  \n",
       "6714                           becoming             documentary  \n",
       "7241                           becoming             documentary  \n",
       "17784                father soldier son         documentary|war  \n",
       "27107            game of thrones s08e06  action|adventure|drama  \n",
       "83744   les plus belles annees dune vie                   drama  \n",
       "109462                        15 august                   drama  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mk = pd.read_csv('info/action.csv',sep='\\t')\n",
    "data_mk.head()\n",
    "data_mk[data_mk['userid']=='h50e7e4eb0891']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tt = data_mk[['userid','programId','title','genres','timeStamp','label']].rename(columns={'userid':'user_id','programId':'movie_id','timeStamp':'timestamp','label':'rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tt = data_tt.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "click len 10851 and exp len 196490, click rate 0.05233407767879966, 1679 movies\n"
     ]
    }
   ],
   "source": [
    "data_tt_click = data_tt[data_tt['rating']=='1']\n",
    "data_tt_exp = data_tt[data_tt['rating']=='0']\n",
    "print('click len {} and exp len {}, click rate {}, {} movies'.format(len(data_tt_click),len(data_tt_exp),float(len(data_tt_click)/len(data_tt)),\n",
    "len(data_tt['movie_id'].unique())))\n",
    "\n",
    "features = ['user_id', 'movie_id']\n",
    "map_dicts = [raw_embed_user_mapping, raw_embed_item_mapping]\n",
    "feature_max_idx = {}\n",
    "for feature, map_dict in zip(features, map_dicts):\n",
    "#     lbe = LabelEncoder()\n",
    "#     data_tt[feature] = lbe.fit_transform(data_tt[feature]) + 1\n",
    "    data_tt[feature] = data_tt[feature].apply(lambda x: map_dict[x])\n",
    "    feature_max_idx[feature] = data_tt[feature].max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # constructu mapping dictionary\n",
    "# raw_user_id_list = list(map(str,data_tt_raw['user_id'].values))\n",
    "# code_user_id_list = list(map(str,data_tt['user_id'].values))\n",
    "# raw_embed_user_id_dict = dict(zip(raw_user_id_list, code_user_id_list))\n",
    "# embed_raw_user_id_dict = dict(zip(code_user_id_list, raw_user_id_list))\n",
    "\n",
    "# raw_item_id_list = list(map(str,data_tt_raw['movie_id'].values))\n",
    "# code_item_id_list = list(map(str,data_tt['movie_id'].values))\n",
    "# raw_embed_item_id_dict = dict(zip(raw_item_id_list, code_item_id_list))\n",
    "# embed_raw_item_id_dict = dict(zip(code_item_id_list, raw_item_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_profile = list(raw_embed_item_mapping.keys())\n",
    "item_profile_encode = []\n",
    "for ele in item_profile:\n",
    "    item_profile_encode.append(raw_embed_item_mapping[ele])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_thred = 2\n",
    "data_tt_filter = data_tt[data_tt['rating']=='1'].groupby(['movie_id']).filter(lambda x: len(x) > count_thred)\n",
    "pass_item_pddf = data_tt_filter.drop_duplicates('movie_id')[['movie_id','rating']]\n",
    "\n",
    "data_tt_click = data_tt[data_tt['rating']=='1']\n",
    "keys = list(pass_item_pddf.columns.values)\n",
    "i1 = data_tt_click.set_index(keys).index\n",
    "i2 = pass_item_pddf.set_index(keys).index\n",
    "data_tt_click = data_tt_click[i1.isin(i2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1779/1779 [00:15<00:00, 117.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/deepctr/layers/utils.py:167: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/deepctr/layers/utils.py:199: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 41142 samples\n",
      "Epoch 1/300\n",
      "41142/41142 [==============================] - 2s 44us/sample - loss: 3.2870\n",
      "Epoch 2/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 2.9953\n",
      "Epoch 3/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 2.9368\n",
      "Epoch 4/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 2.9541\n",
      "Epoch 5/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 2.9003\n",
      "Epoch 6/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 2.9098\n",
      "Epoch 7/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 2.9374\n",
      "Epoch 8/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 2.9526\n",
      "Epoch 9/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.9174\n",
      "Epoch 10/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.9270\n",
      "Epoch 11/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.8908\n",
      "Epoch 12/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.8755\n",
      "Epoch 13/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.9036\n",
      "Epoch 14/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.9183\n",
      "Epoch 15/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.9320\n",
      "Epoch 16/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.9311\n",
      "Epoch 17/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 2.9335\n",
      "Epoch 18/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.8013\n",
      "Epoch 19/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.8005\n",
      "Epoch 20/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.8145\n",
      "Epoch 21/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.7719\n",
      "Epoch 22/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.6639\n",
      "Epoch 23/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.7002\n",
      "Epoch 24/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.6930\n",
      "Epoch 25/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.6645\n",
      "Epoch 26/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.6728\n",
      "Epoch 27/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.5757\n",
      "Epoch 28/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.6245\n",
      "Epoch 29/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.6009\n",
      "Epoch 30/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.5332\n",
      "Epoch 31/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.5652\n",
      "Epoch 32/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 2.5412\n",
      "Epoch 33/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.5012\n",
      "Epoch 34/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.4758\n",
      "Epoch 35/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.4738\n",
      "Epoch 36/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.4960\n",
      "Epoch 37/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.4182\n",
      "Epoch 38/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.3747\n",
      "Epoch 39/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 2.3091\n",
      "Epoch 40/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 2.2783\n",
      "Epoch 41/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.2999\n",
      "Epoch 42/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.2497\n",
      "Epoch 43/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.2884\n",
      "Epoch 44/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.2362\n",
      "Epoch 45/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.2365\n",
      "Epoch 46/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.2024\n",
      "Epoch 47/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.1735\n",
      "Epoch 48/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.1505\n",
      "Epoch 49/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.0622\n",
      "Epoch 50/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 2.1109\n",
      "Epoch 51/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.0444\n",
      "Epoch 52/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 2.1066\n",
      "Epoch 53/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.9711\n",
      "Epoch 54/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.9815\n",
      "Epoch 55/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.9739\n",
      "Epoch 56/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.9371\n",
      "Epoch 57/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.9077\n",
      "Epoch 58/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.8614\n",
      "Epoch 59/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.7396\n",
      "Epoch 60/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.7697\n",
      "Epoch 61/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.8375\n",
      "Epoch 62/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.7484\n",
      "Epoch 63/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.7453\n",
      "Epoch 64/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.6571\n",
      "Epoch 65/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.6881\n",
      "Epoch 66/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.6276\n",
      "Epoch 67/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.6217\n",
      "Epoch 68/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.5978\n",
      "Epoch 69/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.5807\n",
      "Epoch 70/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.5291\n",
      "Epoch 71/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.4705\n",
      "Epoch 72/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.4706\n",
      "Epoch 73/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.3905\n",
      "Epoch 74/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.4552\n",
      "Epoch 75/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.3861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.4208\n",
      "Epoch 77/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.4238\n",
      "Epoch 78/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.3692\n",
      "Epoch 79/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.3133\n",
      "Epoch 80/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.3479\n",
      "Epoch 81/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.2719\n",
      "Epoch 82/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.2256\n",
      "Epoch 83/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.3183\n",
      "Epoch 84/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.3043\n",
      "Epoch 85/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.2570\n",
      "Epoch 86/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.2569\n",
      "Epoch 87/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.2029\n",
      "Epoch 88/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.2580\n",
      "Epoch 89/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.1993\n",
      "Epoch 90/300\n",
      "41142/41142 [==============================] - 1s 18us/sample - loss: 1.1437\n",
      "Epoch 91/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.1167\n",
      "Epoch 92/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.1213\n",
      "Epoch 93/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.1295\n",
      "Epoch 94/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.0905\n",
      "Epoch 95/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.0752\n",
      "Epoch 96/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.1021\n",
      "Epoch 97/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.0724\n",
      "Epoch 98/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.0457\n",
      "Epoch 99/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.0486\n",
      "Epoch 100/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.0647\n",
      "Epoch 101/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.0300\n",
      "Epoch 102/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.9412\n",
      "Epoch 103/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.9922\n",
      "Epoch 104/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.0177\n",
      "Epoch 105/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.9264\n",
      "Epoch 106/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.8986\n",
      "Epoch 107/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.8989\n",
      "Epoch 108/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.8577\n",
      "Epoch 109/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.8696\n",
      "Epoch 110/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.8726\n",
      "Epoch 111/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.8283\n",
      "Epoch 112/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.8904\n",
      "Epoch 113/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.7812\n",
      "Epoch 114/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.7844\n",
      "Epoch 115/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.8315\n",
      "Epoch 116/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.7850\n",
      "Epoch 117/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.7654\n",
      "Epoch 118/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.8093\n",
      "Epoch 119/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.7999\n",
      "Epoch 120/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.7536\n",
      "Epoch 121/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.7365\n",
      "Epoch 122/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.7185\n",
      "Epoch 123/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.7302\n",
      "Epoch 124/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.7392\n",
      "Epoch 125/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.6958\n",
      "Epoch 126/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.6751\n",
      "Epoch 127/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6782\n",
      "Epoch 128/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.6706\n",
      "Epoch 129/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6335\n",
      "Epoch 130/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6589\n",
      "Epoch 131/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.6006\n",
      "Epoch 132/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.5517\n",
      "Epoch 133/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6136\n",
      "Epoch 134/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6149\n",
      "Epoch 135/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6004\n",
      "Epoch 136/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.5373\n",
      "Epoch 137/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5562\n",
      "Epoch 138/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5954\n",
      "Epoch 139/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6187\n",
      "Epoch 140/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5721\n",
      "Epoch 141/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5340\n",
      "Epoch 142/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5625\n",
      "Epoch 143/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.5480\n",
      "Epoch 144/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5178\n",
      "Epoch 145/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5042\n",
      "Epoch 146/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5128\n",
      "Epoch 147/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5840\n",
      "Epoch 148/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5095\n",
      "Epoch 149/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5048\n",
      "Epoch 150/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.4685\n",
      "Epoch 151/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4714\n",
      "Epoch 152/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4912\n",
      "Epoch 153/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4892\n",
      "Epoch 154/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4701\n",
      "Epoch 155/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4472\n",
      "Epoch 156/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5161\n",
      "Epoch 157/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.4902\n",
      "Epoch 158/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.4367\n",
      "Epoch 159/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4800\n",
      "Epoch 160/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4298\n",
      "Epoch 161/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4916\n",
      "Epoch 162/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4325\n",
      "Epoch 163/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4273\n",
      "Epoch 164/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 0.4328\n",
      "Epoch 165/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.4109\n",
      "Epoch 166/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4641\n",
      "Epoch 167/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3874\n",
      "Epoch 168/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3837\n",
      "Epoch 169/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3998\n",
      "Epoch 170/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4240\n",
      "Epoch 171/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4211\n",
      "Epoch 172/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4197\n",
      "Epoch 173/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4264\n",
      "Epoch 174/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.4109\n",
      "Epoch 175/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3990\n",
      "Epoch 176/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4081\n",
      "Epoch 177/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4008\n",
      "Epoch 178/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.4131\n",
      "Epoch 179/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4114\n",
      "Epoch 180/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.3739\n",
      "Epoch 181/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3572\n",
      "Epoch 182/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3804\n",
      "Epoch 183/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3396\n",
      "Epoch 184/300\n",
      "41142/41142 [==============================] - 2s 38us/sample - loss: 0.4200\n",
      "Epoch 185/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.3645\n",
      "Epoch 186/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.3558\n",
      "Epoch 187/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3612\n",
      "Epoch 188/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4014\n",
      "Epoch 189/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3884\n",
      "Epoch 190/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 0.3587\n",
      "Epoch 191/300\n",
      "41142/41142 [==============================] - 2s 37us/sample - loss: 0.3584\n",
      "Epoch 192/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3519\n",
      "Epoch 193/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3560\n",
      "Epoch 194/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.3618\n",
      "Epoch 195/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3537\n",
      "Epoch 196/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.3582\n",
      "Epoch 197/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3626\n",
      "Epoch 198/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3267\n",
      "Epoch 199/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3553\n",
      "Epoch 200/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.3635\n",
      "Epoch 201/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3333\n",
      "Epoch 202/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3575\n",
      "Epoch 203/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3390\n",
      "Epoch 204/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3831\n",
      "Epoch 205/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3142\n",
      "Epoch 206/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3059\n",
      "Epoch 207/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2865\n",
      "Epoch 208/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.3089\n",
      "Epoch 209/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3300\n",
      "Epoch 210/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.3274\n",
      "Epoch 211/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.3115\n",
      "Epoch 212/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2957\n",
      "Epoch 213/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 0.3086\n",
      "Epoch 214/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 0.2946\n",
      "Epoch 215/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 0.3023\n",
      "Epoch 216/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 0.2977\n",
      "Epoch 217/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 0.3028\n",
      "Epoch 218/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 0.3263\n",
      "Epoch 219/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 0.2807\n",
      "Epoch 220/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2957\n",
      "Epoch 221/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.3563\n",
      "Epoch 222/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2965\n",
      "Epoch 223/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.3078\n",
      "Epoch 224/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2999\n",
      "Epoch 225/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2841\n",
      "Epoch 226/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2972\n",
      "Epoch 227/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3081\n",
      "Epoch 228/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3054\n",
      "Epoch 229/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2762\n",
      "Epoch 230/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2697\n",
      "Epoch 231/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2631\n",
      "Epoch 232/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2807\n",
      "Epoch 233/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2804\n",
      "Epoch 234/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2908\n",
      "Epoch 235/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3191\n",
      "Epoch 236/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2545\n",
      "Epoch 237/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2926\n",
      "Epoch 238/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2668\n",
      "Epoch 239/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2740\n",
      "Epoch 240/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3009\n",
      "Epoch 241/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3137\n",
      "Epoch 242/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2945\n",
      "Epoch 243/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2850\n",
      "Epoch 244/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2869\n",
      "Epoch 245/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2668\n",
      "Epoch 246/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2837\n",
      "Epoch 247/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2598\n",
      "Epoch 248/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2805\n",
      "Epoch 249/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2367\n",
      "Epoch 250/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2456\n",
      "Epoch 251/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2363\n",
      "Epoch 252/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2695\n",
      "Epoch 253/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2796\n",
      "Epoch 254/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2579\n",
      "Epoch 255/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2625\n",
      "Epoch 256/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2836\n",
      "Epoch 257/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2830\n",
      "Epoch 258/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2458\n",
      "Epoch 259/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2585\n",
      "Epoch 260/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2324\n",
      "Epoch 261/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2269\n",
      "Epoch 262/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2827\n",
      "Epoch 263/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2433\n",
      "Epoch 264/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2554\n",
      "Epoch 265/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2365\n",
      "Epoch 266/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2448\n",
      "Epoch 267/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2525\n",
      "Epoch 268/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2294\n",
      "Epoch 269/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2488\n",
      "Epoch 270/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2260\n",
      "Epoch 271/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2448\n",
      "Epoch 272/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2365\n",
      "Epoch 273/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2231\n",
      "Epoch 274/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2567\n",
      "Epoch 275/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2336\n",
      "Epoch 276/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2587\n",
      "Epoch 277/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2419\n",
      "Epoch 278/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2291\n",
      "Epoch 279/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2424\n",
      "Epoch 280/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2718\n",
      "Epoch 281/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2627\n",
      "Epoch 282/300\n",
      "41142/41142 [==============================] - 1s 21us/sample - loss: 0.2527\n",
      "Epoch 283/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2545\n",
      "Epoch 284/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2376\n",
      "Epoch 285/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2535\n",
      "Epoch 286/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2618\n",
      "Epoch 287/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2529\n",
      "Epoch 288/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2312\n",
      "Epoch 289/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2434\n",
      "Epoch 290/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2470\n",
      "Epoch 291/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2416\n",
      "Epoch 292/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2337\n",
      "Epoch 293/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2074\n",
      "Epoch 294/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2171\n",
      "Epoch 295/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2442\n",
      "Epoch 296/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2328\n",
      "Epoch 297/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2384\n",
      "Epoch 298/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2344\n",
      "Epoch 299/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2439\n",
      "Epoch 300/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 0.2381\n"
     ]
    }
   ],
   "source": [
    "#data = pd.read_csvdata = pd.read_csv(\"./movielens_sample.txt\")\n",
    "sparse_features = [\"movie_id\", \"user_id\"]\n",
    "SEQ_LEN = 50\n",
    "negsample = 5\n",
    "\n",
    "# 1.Label Encoding for sparse features,and process sequence features with `gen_date_set` and `gen_model_input`\n",
    "user_profile = data_tt[[\"user_id\"]].drop_duplicates('user_id')\n",
    "\n",
    "# item_profile = data_tt.drop_duplicates('movie_id')\n",
    "# item_profile = data[[\"movie_id\"]].drop_duplicates('movie_id')\n",
    "\n",
    "user_profile.set_index(\"user_id\", inplace=True)\n",
    "\n",
    "user_item_list = data_tt.groupby(\"user_id\")['movie_id'].apply(list)\n",
    "\n",
    "# train_set, test_set = gen_data_set(data_tt_click, negsample, data_tt['movie_id'].unique())\n",
    "train_set, test_set = gen_data_set(data_tt_click, negsample, np.array(item_profile_encode))\n",
    "\n",
    "train_model_input, train_label = gen_model_input(train_set, user_profile, SEQ_LEN)\n",
    "test_model_input, test_label = gen_model_input(test_set, user_profile, SEQ_LEN)\n",
    "\n",
    "# 2.count #unique features for each sparse field and generate feature config for sequence feature\n",
    "\n",
    "embedding_dim = 32\n",
    "\n",
    "user_feature_columns = [SparseFeat('user_id', feature_max_idx['user_id'], 16),\n",
    "                        VarLenSparseFeat(SparseFeat('hist_movie_id', feature_max_idx['movie_id'], embedding_dim,\n",
    "                                                    embedding_name=\"movie_id\"), SEQ_LEN, 'mean', 'hist_len'),\n",
    "                        ]\n",
    "\n",
    "item_feature_columns = [SparseFeat('movie_id', feature_max_idx['movie_id'], embedding_dim)]\n",
    "\n",
    "# 3.Define Model and train\n",
    "\n",
    "K.set_learning_phase(True)\n",
    "\n",
    "import tensorflow as tf\n",
    "if tf.__version__ >= '2.0.0':\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "model = YoutubeDNN(user_feature_columns, item_feature_columns, num_sampled=100, user_dnn_hidden_units=(128,64, embedding_dim))\n",
    "# model = MIND(user_feature_columns,item_feature_columns,dynamic_k=False,p=1,k_max=2,num_sampled=100,user_dnn_hidden_units=(128,64, embedding_dim))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=sampledsoftmaxloss)  # \"binary_crossentropy\")\n",
    "\n",
    "history = model.fit(train_model_input, train_label,  # train_label,\n",
    "                    batch_size=512, epochs=300, verbose=1, validation_split=0.0, )\n",
    "\n",
    "# 4. Generate user features for testing and full item features for retrieval\n",
    "test_user_model_input = test_model_input\n",
    "# all_item_model_input = {\"movie_id\": item_profile['movie_id'].values,}\n",
    "all_item_model_input = {\"movie_id\": np.array(item_profile_encode),}\n",
    "\n",
    "user_embedding_model = Model(inputs=model.user_input, outputs=model.user_embedding)\n",
    "item_embedding_model = Model(inputs=model.item_input, outputs=model.item_embedding)\n",
    "\n",
    "user_embs = user_embedding_model.predict(test_user_model_input, batch_size=2 ** 12)\n",
    "# user_embs = user_embs[:, i, :]  # i in [0,k_max) if MIND\n",
    "item_embs = item_embedding_model.predict(all_item_model_input, batch_size=2 ** 12)\n",
    "\n",
    "# print(user_embs.shape)\n",
    "# print(item_embs.shape)\n",
    "# print(user_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1713it [00:00, 49634.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "recall 0.6398131932282545\n",
      "hit rate 0.6398131932282545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "# faiss.normalize_L2(item_embs)\n",
    "index.add(item_embs)\n",
    "# faiss.normalize_L2(user_embs)\n",
    "D, I = index.search(np.ascontiguousarray(user_embs), 50)\n",
    "s = []\n",
    "hit = 0\n",
    "test_cnt = 0\n",
    "\n",
    "test_true_label = {line[0]:[line[2]] for line in test_set}\n",
    "\n",
    "for i, uid in tqdm(enumerate(test_user_model_input['user_id'])):\n",
    "#     try:\n",
    "        pred = [item_profile_encode[x] for x in I[i]]\n",
    "        filter_item = None\n",
    "        recall_score = recall_N(test_true_label[uid], pred, N=50)\n",
    "        s.append(recall_score)\n",
    "#         print(test_true_label[uid])\n",
    "#         print(pred)\n",
    "#         break\n",
    "        if test_true_label[uid][0] in pred:\n",
    "#             if test_cnt < 10:\n",
    "#                 print(\"input {} pred {} and label {}\".format(I[i], pred, test_true_label[uid]))\n",
    "#                 test_cnt = test_cnt + 1\n",
    "            hit += 1\n",
    "#         if recall_score > 0:\n",
    "#             print(\"input {} pred {} and label {}\".format(I[i], pred, test_true_label[uid]))\n",
    "#             test_cnt = test_cnt + 1\n",
    "#     except:\n",
    "#         print(i)\n",
    "print(\"\")\n",
    "print(\"recall\", np.mean(s))\n",
    "print(\"hit rate\", hit / len(test_user_model_input['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储/更新用户嵌入模型\n",
    "file_name = 'info/user_embeddings.h5'\n",
    "save_model(user_embedding_model, file_name)\n",
    "write_to_s3(file_name, bucket, \"{}/model/recall/youtubednn/{}\".format(prefix,file_name.split('/')[-1]))\n",
    "\n",
    "# 存储/更新faiss index\n",
    "file_name = 'info/ub_item_vector.index'\n",
    "faiss.write_index(index, file_name)\n",
    "write_to_s3(file_name, bucket, \"{}/feature/action/{}\".format(prefix,file_name.split('/')[-1]))\n",
    "\n",
    "# # 存储/更新映射pickle文件\n",
    "# file_name = 'info/raw_embed_user_mapping.pickle'\n",
    "# output_file = open(file_name, 'wb')\n",
    "# pickle.dump(raw_embed_user_id_dict, output_file)\n",
    "# output_file.close()\n",
    "# write_to_s3(file_name, bucket, \"{}/feature/action/{}\".format(prefix,file_name.split('/')[-1]))\n",
    "\n",
    "# file_name = 'info/embed_raw_user_mapping.pickle'\n",
    "# output_file = open(file_name, 'wb')\n",
    "# pickle.dump(embed_raw_user_id_dict, output_file)\n",
    "# output_file.close()\n",
    "# write_to_s3(file_name, bucket, \"{}/feature/action/{}\".format(prefix,file_name.split('/')[-1]))\n",
    "\n",
    "# file_name = 'info/raw_embed_item_mapping.pickle'\n",
    "# output_file = open(file_name, 'wb')\n",
    "# pickle.dump(raw_embed_item_id_dict, output_file)\n",
    "# output_file.close()\n",
    "# write_to_s3(file_name, bucket, \"{}/feature/action/{}\".format(prefix,file_name.split('/')[-1]))\n",
    "\n",
    "# file_name = 'info/embed_raw_item_mapping.pickle'\n",
    "# output_file = open(file_name, 'wb')\n",
    "# pickle.dump(embed_raw_item_id_dict, output_file)\n",
    "# output_file.close()\n",
    "# write_to_s3(file_name, bucket, \"{}/feature/action/{}\".format(prefix,file_name.split('/')[-1]))\n",
    "\n",
    "# 存储/更新物品embedding npy\n",
    "file_name = 'info/ub_item_embeddings.npy'\n",
    "with open(file_name,'wb') as f:\n",
    "    np.save(f, item_embs)\n",
    "write_to_s3(file_name, bucket, \"{}/feature/action/{}\".format(prefix,file_name.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "bucket=sagemaker-us-east-1-002224604296\n",
      "prefix='recommender-system-film-mk/1'\n",
      "file preparation: download src key recommender-system-film-mk/1/system/user-data/clean/latest/action.csv to dst key info/action.csv\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/action/raw_embed_item_mapping.pickle to dst key info/raw_embed_item_mapping.pickle\n",
      "file preparation: download src key recommender-system-film-mk/1/feature/action/raw_embed_user_mapping.pickle to dst key info/raw_embed_user_mapping.pickle\n",
      "click len 10851 and exp len 196490, click rate 0.05233407767879966, 1679 movies\n",
      "100%|██████████████████████████████████████| 1779/1779 [00:14<00:00, 122.25it/s]\n",
      "5 6\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/deepctr/layers/utils.py:167: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/deepctr/layers/utils.py:199: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 41142 samples\n",
      "Epoch 1/300\n",
      "41142/41142 [==============================] - 2s 43us/sample - loss: 3.2891\n",
      "Epoch 2/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.9615\n",
      "Epoch 3/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.8937\n",
      "Epoch 4/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.9051\n",
      "Epoch 5/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.9599\n",
      "Epoch 6/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.8879\n",
      "Epoch 7/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.9019\n",
      "Epoch 8/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 2.8259\n",
      "Epoch 9/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.9568\n",
      "Epoch 10/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.8854\n",
      "Epoch 11/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.9213\n",
      "Epoch 12/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.8999\n",
      "Epoch 13/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.9525\n",
      "Epoch 14/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.9122\n",
      "Epoch 15/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.9262\n",
      "Epoch 16/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.9244\n",
      "Epoch 17/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.8690\n",
      "Epoch 18/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 3.0093\n",
      "Epoch 19/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.8269\n",
      "Epoch 20/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.7772\n",
      "Epoch 21/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.8021\n",
      "Epoch 22/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.7240\n",
      "Epoch 23/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.7330\n",
      "Epoch 24/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.7093\n",
      "Epoch 25/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.7163\n",
      "Epoch 26/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.7193\n",
      "Epoch 27/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.6699\n",
      "Epoch 28/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.6673\n",
      "Epoch 29/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.6872\n",
      "Epoch 30/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.6423\n",
      "Epoch 31/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.5872\n",
      "Epoch 32/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.5622\n",
      "Epoch 33/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.4942\n",
      "Epoch 34/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.4738\n",
      "Epoch 35/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.4812\n",
      "Epoch 36/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.5201\n",
      "Epoch 37/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.4724\n",
      "Epoch 38/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.4595\n",
      "Epoch 39/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.4054\n",
      "Epoch 40/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.4468\n",
      "Epoch 41/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.3564\n",
      "Epoch 42/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.4109\n",
      "Epoch 43/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.4242\n",
      "Epoch 44/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.4106\n",
      "Epoch 45/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.3257\n",
      "Epoch 46/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.3294\n",
      "Epoch 47/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.3033\n",
      "Epoch 48/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.2485\n",
      "Epoch 49/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.1336\n",
      "Epoch 50/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.1000\n",
      "Epoch 51/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.1714\n",
      "Epoch 52/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.1383\n",
      "Epoch 53/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.0593\n",
      "Epoch 54/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 2.0134\n",
      "Epoch 55/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.9913\n",
      "Epoch 56/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.9382\n",
      "Epoch 57/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.9997\n",
      "Epoch 58/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.9240\n",
      "Epoch 59/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.8840\n",
      "Epoch 60/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.8990\n",
      "Epoch 61/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.8933\n",
      "Epoch 62/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.8427\n",
      "Epoch 63/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.8456\n",
      "Epoch 64/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.7798\n",
      "Epoch 65/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.8158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.7840\n",
      "Epoch 67/300\n",
      "41142/41142 [==============================] - 1s 16us/sample - loss: 1.7198\n",
      "Epoch 68/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.7284\n",
      "Epoch 69/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.7183\n",
      "Epoch 70/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.6704\n",
      "Epoch 71/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.6898\n",
      "Epoch 72/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.6016\n",
      "Epoch 73/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.6147\n",
      "Epoch 74/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.5576\n",
      "Epoch 75/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.5489\n",
      "Epoch 76/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.5311\n",
      "Epoch 77/300\n",
      "41142/41142 [==============================] - 1s 17us/sample - loss: 1.5145\n",
      "Epoch 78/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.4480\n",
      "Epoch 79/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.4459\n",
      "Epoch 80/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.4078\n",
      "Epoch 81/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.4343\n",
      "Epoch 82/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.4354\n",
      "Epoch 83/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.3323\n",
      "Epoch 84/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.3718\n",
      "Epoch 85/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.3479\n",
      "Epoch 86/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.2707\n",
      "Epoch 87/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.3275\n",
      "Epoch 88/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.2658\n",
      "Epoch 89/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.2622\n",
      "Epoch 90/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.1868\n",
      "Epoch 91/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.2457\n",
      "Epoch 92/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.2288\n",
      "Epoch 93/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.1500\n",
      "Epoch 94/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.1895\n",
      "Epoch 95/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.0998\n",
      "Epoch 96/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.1508\n",
      "Epoch 97/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.0704\n",
      "Epoch 98/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.0819\n",
      "Epoch 99/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.0844\n",
      "Epoch 100/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.1064\n",
      "Epoch 101/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.0867\n",
      "Epoch 102/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.0529\n",
      "Epoch 103/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.0545\n",
      "Epoch 104/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.0356\n",
      "Epoch 105/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.9886\n",
      "Epoch 106/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 1.0925\n",
      "Epoch 107/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.9873\n",
      "Epoch 108/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.9460\n",
      "Epoch 109/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.9174\n",
      "Epoch 110/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.9580\n",
      "Epoch 111/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.9490\n",
      "Epoch 112/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.9103\n",
      "Epoch 113/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.9346\n",
      "Epoch 114/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.9496\n",
      "Epoch 115/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.9191\n",
      "Epoch 116/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.9074\n",
      "Epoch 117/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.8997\n",
      "Epoch 118/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.8446\n",
      "Epoch 119/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.8272\n",
      "Epoch 120/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.8771\n",
      "Epoch 121/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.8679\n",
      "Epoch 122/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.8270\n",
      "Epoch 123/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.8083\n",
      "Epoch 124/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.7608\n",
      "Epoch 125/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.7554\n",
      "Epoch 126/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.7444\n",
      "Epoch 127/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.7201\n",
      "Epoch 128/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.7435\n",
      "Epoch 129/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.7584\n",
      "Epoch 130/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.7414\n",
      "Epoch 131/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.7610\n",
      "Epoch 132/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.7215\n",
      "Epoch 133/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.7252\n",
      "Epoch 134/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.7071\n",
      "Epoch 135/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.7116\n",
      "Epoch 136/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6757\n",
      "Epoch 137/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6539\n",
      "Epoch 138/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6111\n",
      "Epoch 139/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6634\n",
      "Epoch 140/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6980\n",
      "Epoch 141/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6620\n",
      "Epoch 142/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5890\n",
      "Epoch 143/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6434\n",
      "Epoch 144/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6586\n",
      "Epoch 145/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6361\n",
      "Epoch 146/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5900\n",
      "Epoch 147/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6370\n",
      "Epoch 148/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6203\n",
      "Epoch 149/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6089\n",
      "Epoch 150/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5812\n",
      "Epoch 151/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6365\n",
      "Epoch 152/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5988\n",
      "Epoch 153/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.6230\n",
      "Epoch 154/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5497\n",
      "Epoch 155/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5243\n",
      "Epoch 156/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5041\n",
      "Epoch 157/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4917\n",
      "Epoch 158/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5118\n",
      "Epoch 159/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5618\n",
      "Epoch 160/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5311\n",
      "Epoch 161/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5358\n",
      "Epoch 162/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5390\n",
      "Epoch 163/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5147\n",
      "Epoch 164/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4922\n",
      "Epoch 165/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5283\n",
      "Epoch 166/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4660\n",
      "Epoch 167/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5069\n",
      "Epoch 168/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4994\n",
      "Epoch 169/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4982\n",
      "Epoch 170/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4619\n",
      "Epoch 171/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.5172\n",
      "Epoch 172/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4548\n",
      "Epoch 173/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4565\n",
      "Epoch 174/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4940\n",
      "Epoch 175/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4678\n",
      "Epoch 176/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4668\n",
      "Epoch 177/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4671\n",
      "Epoch 178/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4307\n",
      "Epoch 179/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4304\n",
      "Epoch 180/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4046\n",
      "Epoch 181/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4182\n",
      "Epoch 182/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4399\n",
      "Epoch 183/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4518\n",
      "Epoch 184/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4354\n",
      "Epoch 185/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4773\n",
      "Epoch 186/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4257\n",
      "Epoch 187/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4138\n",
      "Epoch 188/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3825\n",
      "Epoch 189/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4462\n",
      "Epoch 190/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4055\n",
      "Epoch 191/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4141\n",
      "Epoch 192/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4037\n",
      "Epoch 193/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4063\n",
      "Epoch 194/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3974\n",
      "Epoch 195/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4224\n",
      "Epoch 196/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.4022\n",
      "Epoch 197/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3839\n",
      "Epoch 198/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3675\n",
      "Epoch 199/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3972\n",
      "Epoch 200/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3872\n",
      "Epoch 201/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3629\n",
      "Epoch 202/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3685\n",
      "Epoch 203/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3612\n",
      "Epoch 204/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3910\n",
      "Epoch 205/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3943\n",
      "Epoch 206/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3406\n",
      "Epoch 207/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3748\n",
      "Epoch 208/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3728\n",
      "Epoch 209/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3651\n",
      "Epoch 210/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3509\n",
      "Epoch 211/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3416\n",
      "Epoch 212/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3341\n",
      "Epoch 213/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3662\n",
      "Epoch 214/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3376\n",
      "Epoch 215/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3616\n",
      "Epoch 216/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3533\n",
      "Epoch 217/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3329\n",
      "Epoch 218/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3583\n",
      "Epoch 219/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3073\n",
      "Epoch 220/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3556\n",
      "Epoch 221/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3780\n",
      "Epoch 222/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3183\n",
      "Epoch 223/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3267\n",
      "Epoch 224/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3418\n",
      "Epoch 225/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3155\n",
      "Epoch 226/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3523\n",
      "Epoch 227/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3169\n",
      "Epoch 228/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3464\n",
      "Epoch 229/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3325\n",
      "Epoch 230/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3256\n",
      "Epoch 231/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3444\n",
      "Epoch 232/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3455\n",
      "Epoch 233/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3271\n",
      "Epoch 234/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3168\n",
      "Epoch 235/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3258\n",
      "Epoch 236/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3383\n",
      "Epoch 237/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2873\n",
      "Epoch 238/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2879\n",
      "Epoch 239/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2965\n",
      "Epoch 240/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3117\n",
      "Epoch 241/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3112\n",
      "Epoch 242/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3217\n",
      "Epoch 243/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2978\n",
      "Epoch 244/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2765\n",
      "Epoch 245/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2876\n",
      "Epoch 246/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3394\n",
      "Epoch 247/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3021\n",
      "Epoch 248/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3117\n",
      "Epoch 249/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3136\n",
      "Epoch 250/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2908\n",
      "Epoch 251/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3047\n",
      "Epoch 252/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2748\n",
      "Epoch 253/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2808\n",
      "Epoch 254/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2654\n",
      "Epoch 255/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2677\n",
      "Epoch 256/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3023\n",
      "Epoch 257/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2903\n",
      "Epoch 258/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2958\n",
      "Epoch 259/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2830\n",
      "Epoch 260/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2882\n",
      "Epoch 261/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3016\n",
      "Epoch 262/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2582\n",
      "Epoch 263/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2594\n",
      "Epoch 264/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2859\n",
      "Epoch 265/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2816\n",
      "Epoch 266/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2601\n",
      "Epoch 267/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3000\n",
      "Epoch 268/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2921\n",
      "Epoch 269/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2614\n",
      "Epoch 270/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3229\n",
      "Epoch 271/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2659\n",
      "Epoch 272/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3148\n",
      "Epoch 273/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2736\n",
      "Epoch 274/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2712\n",
      "Epoch 275/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2505\n",
      "Epoch 276/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2664\n",
      "Epoch 277/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2600\n",
      "Epoch 278/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2504\n",
      "Epoch 279/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2488\n",
      "Epoch 280/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2824\n",
      "Epoch 281/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2444\n",
      "Epoch 282/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2952\n",
      "Epoch 283/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2985\n",
      "Epoch 284/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.3048\n",
      "Epoch 285/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2977\n",
      "Epoch 286/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2807\n",
      "Epoch 287/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2544\n",
      "Epoch 288/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2551\n",
      "Epoch 289/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2541\n",
      "Epoch 290/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2515\n",
      "Epoch 291/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2432\n",
      "Epoch 292/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2638\n",
      "Epoch 293/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2898\n",
      "Epoch 294/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2613\n",
      "Epoch 295/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2467\n",
      "Epoch 296/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2687\n",
      "Epoch 297/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2488\n",
      "Epoch 298/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2450\n",
      "Epoch 299/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2573\n",
      "Epoch 300/300\n",
      "41142/41142 [==============================] - 1s 15us/sample - loss: 0.2425\n",
      "1713it [00:00, 47728.72it/s]\n",
      "\n",
      "recall 0.6596614127262114\n",
      "hit rate 0.6596614127262114\n"
     ]
    }
   ],
   "source": [
    "!rm -r info/*\n",
    "!python model-update-ub.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
